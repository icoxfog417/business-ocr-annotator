# Implementation Tasks

**Project**: Business OCR Annotator
**Last Updated**: 2026-01-11
**Status**: Sprint 2 (AI-Assisted Annotation)
**Approach**: Agile Incremental Development
**Reference**: See [spec/proposals/20260107_reorganize_tasks_agile_approach.md](proposals/20260107_reorganize_tasks_agile_approach.md)

## Task Status Legend

- â¬œ **TODO**: Not started
- ðŸ”„ **IN PROGRESS**: Currently being worked on
- âœ… **DONE**: Completed
- ðŸš« **BLOCKED**: Waiting on dependencies or external factors
- â¸ï¸ **ON HOLD**: Paused temporarily

---

## Agile Development Approach

This task list is organized into **sprints** that deliver working software incrementally. Each sprint includes both frontend and backend tasks necessary to deliver a complete, deployable feature.

**Key Principles:**
- Each sprint delivers a working, deployable application
- Frontend and backend tasks are integrated within each sprint
- User feedback is collected after key sprints (1, 2, 3)
- Infrastructure is built incrementally as needed for features
- Complexity is added gradually based on validated learning

---

## Sprint 0: Foundation & Deployment

**Goal**: Deploy a working authenticated "Hello World" app to AWS
**Duration**: 1-2 weeks
**Deliverable**: Users can log in and see an empty dashboard

### Project Initialization
- âœ… Create React app with Vite and TypeScript
  ```bash
  # Create Vite project (this downloads create-vite temporarily via npx)
  npm create vite@latest business-ocr-annotator -- --template react-ts

  # Enter project directory
  cd business-ocr-annotator

  # Install base dependencies (React, Vite, TypeScript, etc.)
  npm install
  ```

- âœ… Initialize Amplify Gen2 project
  ```bash
  # Add Amplify to existing project (run from project root)
  npm create amplify@latest
  ```
  This creates the `amplify/` directory structure:
  - `amplify/auth/resource.ts`
  - `amplify/data/resource.ts`
  - `amplify/backend.ts`

### Development Environment Setup
- âœ… Install essential dependencies only
  ```bash
  # Install Amplify client libraries (REQUIRED)
  npm install aws-amplify @aws-amplify/ui-react

  # Install Amplify backend development tools (REQUIRED)
  npm install --save-dev @aws-amplify/backend @aws-amplify/backend-cli

  # Install React Router for navigation (REQUIRED)
  npm install react-router-dom

  # Install linting and formatting tools for code quality (REQUIRED)
  npm install --save-dev eslint @typescript-eslint/parser @typescript-eslint/eslint-plugin
  npm install --save-dev prettier eslint-config-prettier eslint-plugin-react-hooks

  # Install git hooks for automated quality checks (REQUIRED)
  npm install --save-dev husky lint-staged
  ```

- âœ… Create ESLint configuration `eslint.config.js`
  ```javascript
  module.exports = {
    root: true,
    env: { browser: true, es2020: true },
    extends: [
      'eslint:recommended',
      'plugin:@typescript-eslint/recommended',
      'plugin:react-hooks/recommended',
      'prettier'
    ],
    ignorePatterns: ['dist', '.eslintrc.cjs', 'amplify_outputs.json'],
    parser: '@typescript-eslint/parser',
    plugins: ['react-hooks'],
  };
  ```

- âœ… Create Prettier configuration `.prettierrc`
  ```json
  {
    "semi": true,
    "trailingComma": "es5",
    "singleQuote": true,
    "printWidth": 100,
    "tabWidth": 2
  }
  ```

- âœ… Add lint scripts to `package.json`
  ```json
  {
    "scripts": {
      "lint": "eslint . --ext ts,tsx --report-unused-disable-directives --max-warnings 0",
      "format": "prettier --write \"src/**/*.{ts,tsx,css}\""
    }
  }
  ```

- âœ… Set up Husky for git hooks
  ```bash
  npx husky init
  echo "npm run lint-staged" > .husky/pre-commit
  ```

- âœ… Configure lint-staged in `package.json`
  ```json
  {
    "lint-staged": {
      "*.{ts,tsx}": [
        "prettier --write",
        "eslint --fix"
      ],
      "*.{css,json,md}": [
        "prettier --write"
      ]
    }
  }
  ```

**Note**: Git hooks automatically run linting and formatting before each commit to maintain code quality.

### Authentication Setup (Amplify Gen2)
- âœ… Set up Google OAuth credentials
  - Go to [Google Cloud Console](https://console.cloud.google.com/)
  - Create a new project or use existing one
  - Enable Google+ API
  - Create OAuth 2.0 credentials (OAuth client ID)
  - Add authorized redirect URIs (Amplify will provide these)
  - Save Client ID and Client Secret

- âœ… Configure Google OAuth in `amplify/auth/resource.ts`
  ```typescript
  import { defineAuth } from '@aws-amplify/backend';

  export const auth = defineAuth({
    loginWith: {
      externalProviders: {
        google: {
          clientId: process.env.GOOGLE_CLIENT_ID!,
          clientSecret: process.env.GOOGLE_CLIENT_SECRET!,
        },
        callbackUrls: [
          'http://localhost:5173',  // Vite dev server
          'https://your-app-domain.amplifyapp.com'  // Production
        ],
        logoutUrls: [
          'http://localhost:5173',
          'https://your-app-domain.amplifyapp.com'
        ]
      }
    }
  });
  ```

- âœ… Add Google credentials to environment
  ```bash
  # For local development
  npx ampx sandbox secret set GOOGLE_CLIENT_ID
  npx ampx sandbox secret set GOOGLE_CLIENT_SECRET
  ```
- âœ… Update `amplify/backend.ts` to include auth
  ```typescript
  import { defineBackend } from '@aws-amplify/backend';
  import { auth } from './auth/resource';

  defineBackend({
    auth
  });
  ```
- âœ… Configure Amplify client in frontend
  ```typescript
  // In src/main.tsx
  import { Amplify } from 'aws-amplify';
  import outputs from '../amplify_outputs.json';

  Amplify.configure(outputs);
  ```

- âœ… Add Google OAuth sign-in to App.tsx
  ```typescript
  import { Authenticator } from '@aws-amplify/ui-react';
  import '@aws-amplify/ui-react/styles.css';

  // The Authenticator will automatically show Google sign-in button
  function App() {
    return (
      <Authenticator socialProviders={['google']}>
        {({ signOut, user }) => (
          <main>
            <h1>Hello {user?.username}</h1>
            <button onClick={signOut}>Sign out</button>
          </main>
        )}
      </Authenticator>
    );
  }
  ```

### Basic Frontend Structure
- âœ… Create main layout component with navigation
- âœ… Create empty Dashboard page
- âœ… Set up React Router v6 (already installed above)
- âœ… Implement authenticated routing wrapper
- âœ… Add logout functionality

### Deployment & Testing
- âœ… Start local sandbox environment
  ```bash
  npx ampx sandbox
  ```
- âœ… Test authentication flow locally
- âœ… Configure AWS credentials
  ```bash
  aws configure
  ```
- âœ… Deploy to Amplify Hosting
- âœ… Verify authentication works in deployed app

### Documentation
- âœ… Create README.md
- âœ… Create CLAUDE.md for agent workflow
- âœ… Create spec/requirements.md
- âœ… Create spec/design.md
- âœ… Create spec/tasks.md
- â¬œ Create CONTRIBUTING.md
- â¬œ Create LICENSE file
- â¬œ Document Sprint 0 setup process

**Sprint 0 Acceptance Criteria:**
- âœ… App deployed to AWS Amplify
- âœ… Users can sign in with Google account
- âœ… Users can log out
- âœ… Authenticated users see a dashboard (even if empty)
- âœ… Sandbox environment working locally
- âœ… Google OAuth credentials configured securely

---

## Sprint 1: Image Upload & Manual Annotation (MVP) - âœ… COMPLETED

**Goal**: Upload images and create annotations manually (no AI yet)
**Duration**: 2-3 weeks
**Deliverable**: Working annotation tool with manual Q&A entry

### Storage Setup (Amplify Gen2)
- âœ… Create `amplify/storage/resource.ts`
- âœ… Update `amplify/backend.ts` to include storage
- âœ… Test S3 upload functionality in sandbox

### Data Model Setup (Amplify Gen2)
- âœ… Define minimal data schema in `amplify/data/resource.ts`
- âœ… Add Image and Annotation models with relationships
- âœ… Update `amplify/backend.ts` to include data
- âœ… Generate GraphQL client types
- âœ… Test data operations in sandbox

### Image Upload UI
- âœ… Create FileUpload page with native drag-and-drop
- âœ… Implement file validation (type, size â‰¤20MB)
- âœ… Add image preview before upload using FileReader API
- âœ… Implement S3 upload using Amplify Storage
- âœ… Save image metadata to DynamoDB via GraphQL
- âœ… Show upload progress indicator
- âœ… Handle upload errors with retry option

### Image Gallery UI
- âœ… Create ImageGallery page
- âœ… Implement image grid with lazy loading
- âœ… Fetch images from GraphQL API
- âœ… Display image thumbnails using S3 presigned URLs
- âœ… Add click to open annotation workspace
- âœ… Implement basic filtering (date, uploaded by)
- âœ… Add image deletion functionality

### Manual Annotation Workspace
- âœ… Create AnnotationWorkspace page with layout
- âœ… Implement ImageViewer component
  - âœ… Display full-size image from S3
  - âœ… Add zoom controls (zoom in, out, reset, fit)
  - âœ… Implement pan functionality
- âœ… Create CanvasAnnotator for bounding boxes
  - âœ… Render image with HTML5 canvas overlay
  - âœ… Implement drag-to-create bounding box
  - âœ… Implement box selection (click to select)
  - âœ… Add delete box functionality
  - âœ… Store coordinates in pixels {x, y, width, height}
- âœ… Create AnnotationForm component
  - âœ… QuestionInput text field
  - âœ… AnswerInput text field
  - âœ… Associate annotation with selected bounding box
  - âœ… Display bounding box coordinates
- âœ… Create AnnotationList component
  - âœ… Display all annotations for current image
  - âœ… Click annotation to highlight its bounding box
  - âœ… Edit/delete existing annotations
- âœ… Implement save functionality (save to DynamoDB via GraphQL)

### Dashboard Updates
- âœ… Display total images count
- âœ… Display total annotations count
- âœ… Show recent uploads list
- âœ… Add navigation to Upload and Gallery pages

**Sprint 1 Acceptance Criteria:**
- âœ… Users can upload images (single or batch)
- âœ… Uploaded images appear in gallery
- âœ… Users can open annotation workspace
- âœ… Users can draw bounding boxes on images
- âœ… Users can manually enter questions and answers
- âœ… Annotations are saved and persisted
- âœ… Users can view, edit, and delete annotations
- âœ… Dashboard shows basic statistics
- âœ… Zoom and pan controls work in annotation workspace
- âœ… GraphQL types are generated and working
- âœ… Sandbox deployment is successful

---

## Sprint 2: AI-Assisted Annotation (Nemotron Integration)

**Goal**: Auto-generate annotations using NVIDIA Nemotron Nano 12B
**Duration**: 2-3 weeks
**Deliverable**: One-click AI annotation generation

### Nemotron Setup
- â¬œ Research NVIDIA Nemotron Nano 12B deployment options
- â¬œ Set up Nemotron model endpoint (self-hosted or API)
- â¬œ Configure IAM permissions for Nemotron access
- â¬œ Test model inference with sample images

### Lambda Function for Annotation Generation
- â¬œ Create `amplify/functions/generate-annotation/` directory
- â¬œ Initialize function package
  ```bash
  cd amplify/functions/generate-annotation
  npm init -y
  npm install @aws-sdk/client-s3
  cd ../../..
  ```
- â¬œ Create `amplify/functions/generate-annotation/resource.ts`
  ```typescript
  import { defineFunction } from '@aws-amplify/backend';

  export const generateAnnotation = defineFunction({
    name: 'generateAnnotation',
    runtime: 20, // Node.js 20.x
    timeoutSeconds: 300, // 5 minutes for Nemotron call
    memoryMB: 1024
  });
  ```
- â¬œ Implement handler in `amplify/functions/generate-annotation/handler.ts`
  ```typescript
  import { NemotronVisionClient } from './nemotron-client';
  ```
- â¬œ Implement NemotronVisionClient service class
  - â¬œ Initialize Nemotron client
  - â¬œ Create prompt template for Nemotron Nano 12B
  - â¬œ Implement API call with image (base64 or S3 reference)
  - â¬œ Parse response to extract Q&A pairs and bounding boxes
- â¬œ Add Lambda environment variables
  ```typescript
  // In resource.ts
  environment: {
    NEMOTRON_ENDPOINT: 'https://api.nemotron.nvidia.com/v1',
    MODEL_ID: 'nvidia/nemotron-nano-12b'
  }
  ```
- â¬œ Grant Lambda permissions to access S3 and Nemotron API
- â¬œ Store generated annotations in DynamoDB
- â¬œ Add error handling and retry logic
- â¬œ Implement CloudWatch logging

### Update Backend Configuration
- â¬œ Update `amplify/backend.ts` to include function
  ```typescript
  import { generateAnnotation } from './functions/generate-annotation/resource';

  defineBackend({
    auth,
    storage,
    data,
    generateAnnotation
  });
  ```
- â¬œ Add GraphQL custom query/mutation for annotation generation
- â¬œ Test Lambda function in sandbox
  ```bash
  npx ampx sandbox --stream-function-logs
  ```

### Frontend Integration
- â¬œ Add "Generate Annotations" button to AnnotationWorkspace
- â¬œ Implement API call to Lambda function
  ```typescript
  import { generateClient } from 'aws-amplify/api';
  ```
- â¬œ Show loading state during generation (with spinner)
- â¬œ Display generated annotations in AnnotationList
- â¬œ Allow users to edit/approve/reject AI annotations
- â¬œ Add confidence score display (if available from Nemotron)
- â¬œ Highlight AI-generated vs manual annotations
- â¬œ Handle generation errors gracefully

### Annotation Validation UI
- â¬œ Create ValidationControls component
  - â¬œ Approve button (green checkmark)
  - â¬œ Reject button (red X)
  - â¬œ Edit button (pencil icon)
- â¬œ Track annotation status (pending, approved, rejected)
- â¬œ Update data model to include status field
- â¬œ Filter annotations by status in AnnotationList

**Sprint 2 Acceptance Criteria:**
- âœ… Users can click "Generate Annotations" button
- âœ… AI generates Q&A pairs with bounding boxes
- âœ… Generated annotations appear in the workspace
- âœ… Users can approve, reject, or edit AI annotations
- âœ… Annotation status is tracked and persisted
- âœ… Error handling works for Nemotron failures

---

## Sprint 3: Dataset Management, Export & Validation

**Goal**: Create datasets, export in JSON format, and validate quality with W&B
**Duration**: 2-3 weeks
**Deliverable**: Dataset creation, export functionality, and W&B-based evaluation

### Data Model Extension
- â¬œ Add Dataset model to `amplify/data/resource.ts`
  ```typescript
  Dataset: a.model({
    name: a.string().required(),
    description: a.string(),
    version: a.string().required(),
    createdBy: a.string().required(),
    createdAt: a.datetime().required(),
    imageCount: a.integer(),
    annotationCount: a.integer()
  }).authorization((allow) => [allow.authenticated()])
  ```
- â¬œ Add relationship: Image belongs to Dataset
- â¬œ Add relationship: Annotation belongs to Image
- â¬œ Deploy schema updates
  ```bash
  npx ampx sandbox
  ```

### Dataset Management UI
- â¬œ Create DatasetList page
  - â¬œ Display all datasets in a grid/list
  - â¬œ Show dataset metadata (name, version, count)
  - â¬œ Add "Create New Dataset" button
- â¬œ Create DatasetForm dialog
  - â¬œ Name input field
  - â¬œ Description textarea
  - â¬œ Version input field
  - â¬œ Select images to include (multi-select)
- â¬œ Implement dataset creation (save to DynamoDB)
- â¬œ Create DatasetDetails page
  - â¬œ Display dataset metadata
  - â¬œ Show included images and annotations
  - â¬œ Display statistics (total Q&A pairs, image count)
  - â¬œ Add edit/delete dataset functionality

### Export Lambda Function
- â¬œ Create `amplify/functions/export-dataset/` directory
- â¬œ Create `amplify/functions/export-dataset/resource.ts`
  ```typescript
  import { defineFunction } from '@aws-amplify/backend';

  export const exportDataset = defineFunction({
    name: 'exportDataset',
    runtime: 20,
    timeoutSeconds: 300,
    memoryMB: 2048
  });
  ```
- â¬œ Implement handler in `amplify/functions/export-dataset/handler.ts`
  - â¬œ Fetch dataset data from DynamoDB
  - â¬œ Fetch associated images and annotations
  - â¬œ Transform to JSON format (simple structure)
  - â¬œ Upload export file to S3
  - â¬œ Return presigned URL for download
- â¬œ Add error handling and validation
- â¬œ Update `amplify/backend.ts` to include function

### Export UI
- â¬œ Add "Export Dataset" button to DatasetDetails page
- â¬œ Create ExportDialog component
  - â¬œ Format selection (JSON only for now)
  - â¬œ Show export progress
  - â¬œ Display download link when ready
- â¬œ Implement download functionality
- â¬œ Handle export errors

### Dashboard Enhancements
- â¬œ Display total datasets count
- â¬œ Show recent datasets list
- â¬œ Add quick actions (Create Dataset, Upload Image)

### Weights & Biases Integration
- â¬œ Set up W&B account and project
  ```bash
  pip install wandb
  wandb login
  ```
- â¬œ Store W&B API key in AWS Secrets Manager
  ```bash
  printf "your-wandb-api-key" | npx ampx sandbox secret set WANDB_API_KEY
  ```
- â¬œ Create `amplify/functions/wandb-logger/` directory
- â¬œ Create `amplify/functions/wandb-logger/resource.ts`
  ```typescript
  import { defineFunction, secret } from '@aws-amplify/backend';

  export const wandbLogger = defineFunction({
    name: 'wandbLogger',
    runtime: 20,
    timeoutSeconds: 300,
    memoryMB: 1024,
    environment: {
      WANDB_API_KEY: secret('WANDB_API_KEY'),
      WANDB_PROJECT: 'business-ocr-dataset'
    }
  });
  ```
- â¬œ Install dependencies in function directory
  ```bash
  cd amplify/functions/wandb-logger
  npm install wandb
  ```
- â¬œ Implement incremental data logging handler
  - â¬œ Initialize W&B run
  - â¬œ Create W&B Table for VQA data
  - â¬œ Log images incrementally (one row at a time to avoid memory issues)
  - â¬œ Include fields: image, question, answers, answer_bbox, document_type
  - â¬œ Handle large image files (compress if needed before upload)
  - â¬œ Track logging progress
  - â¬œ Return W&B run URL
- â¬œ Implement evaluation handler
  - â¬œ Fetch dataset from DynamoDB
  - â¬œ Create evaluation run in W&B
  - â¬œ Log evaluation metrics incrementally (per annotation)
  - â¬œ Calculate OCR accuracy metrics (exact match, F1 score)
  - â¬œ Visualize bounding box annotations
  - â¬œ Compare annotation quality across images
  - â¬œ Return evaluation summary and W&B URL
- â¬œ Update `amplify/backend.ts` to include wandbLogger function

### W&B Integration UI
- â¬œ Add "Log to W&B" button to DatasetDetails page
- â¬œ Create WandBDialog component
  - â¬œ Project name input
  - â¬œ Run name input (auto-generated by default)
  - â¬œ Show logging progress (X/Y images logged)
  - â¬œ Display W&B run URL when complete
- â¬œ Add "Evaluate Dataset" button
- â¬œ Create EvaluationDialog component
  - â¬œ Select metrics to compute
  - â¬œ Show evaluation progress
  - â¬œ Display evaluation results summary
  - â¬œ Link to W&B evaluation dashboard
- â¬œ Handle W&B API errors gracefully
- â¬œ Store W&B run URLs in dataset metadata

**Sprint 3 Acceptance Criteria:**
- âœ… Users can create new datasets
- âœ… Users can add images to datasets
- âœ… Datasets are listed and searchable
- âœ… Users can view dataset details
- âœ… Users can export datasets in JSON format
- âœ… Export file is downloadable
- âœ… Datasets can be logged to W&B incrementally
- âœ… Large images are handled without memory issues
- âœ… Evaluations can be run on datasets
- âœ… Evaluation metrics are displayed in W&B
- âœ… W&B run URLs are saved and accessible

---

## Sprint 4: Multi-Language Support & Image Optimization

**Goal**: Support multiple languages and optimize image storage
**Duration**: 2 weeks
**Deliverable**: Multi-language annotation + image compression

### Multi-Language Data Model
- â¬œ Add language field to Image model
  ```typescript
  language: a.enum(['ja', 'en', 'zh', 'ko']).required()
  ```
- â¬œ Add language field to Annotation model
- â¬œ Add GSI on language field for filtering
- â¬œ Deploy schema updates

### Multi-Language UI
- â¬œ Add language selection to Upload page
  - â¬œ Language dropdown (Japanese, English, Chinese, Korean)
  - â¬œ Make language required field
  - â¬œ Display selected language prominently
- â¬œ Add language filter to Image Gallery
- â¬œ Display language badge on image cards
- â¬œ (Optional) Set up i18n framework for UI localization
  ```bash
  # Only if you need multi-language UI (not required for MVP)
  npm install react-i18next i18next
  ```
  Note: Can start with English-only UI and add translations later if needed

### Multi-Language Nemotron Prompts
- â¬œ Create prompt templates directory `amplify/functions/generate-annotation/prompts/`
  - â¬œ `ja.ts` - Japanese prompt template
  - â¬œ `en.ts` - English prompt template
  - â¬œ `zh.ts` - Chinese prompt template
  - â¬œ `ko.ts` - Korean prompt template
- â¬œ Update NemotronVisionClient to select prompt by language
- â¬œ Add language parameter to annotation generation Lambda
- â¬œ Test prompts for each language
- â¬œ Update Lambda environment variables
  ```typescript
  SUPPORTED_LANGUAGES: 'ja,en,zh,ko'
  ```

### Additional Bedrock Models
- â¬œ Request model access for Qwen-VL
- â¬œ Add model selection to annotation generation
- â¬œ Update BedrockVisionClient to support multiple models
  - â¬œ Claude 3.5 Sonnet (current)
  - â¬œ Qwen-VL (new)
- â¬œ Add model configuration to settings

### Image Compression Lambda
- â¬œ Create `amplify/functions/image-processor/` directory
- â¬œ Create `amplify/functions/image-processor/resource.ts`
  ```typescript
  import { defineFunction } from '@aws-amplify/backend';

  export const imageProcessor = defineFunction({
    name: 'imageProcessor',
    runtime: 20,
    timeoutSeconds: 300,
    memoryMB: 1536
  });
  ```
- â¬œ Install Sharp library
  ```bash
  cd amplify/functions/image-processor
  npm install sharp
  ```
- â¬œ Implement handler
  - â¬œ Extract image metadata (width, height, size)
  - â¬œ Implement smart compression (â‰¤4MB target)
    - â¬œ Dynamic quality adjustment
    - â¬œ Max dimension 2048px
    - â¬œ Maintain aspect ratio
  - â¬œ Generate thumbnail (â‰¤100KB, 200x200px)
  - â¬œ Upload compressed and thumbnail to S3
  - â¬œ Update Image record with all versions
- â¬œ Configure S3 trigger for original/ folder
- â¬œ Add S3 folder structure: `original/`, `compressed/`, `thumbnail/`
- â¬œ Update `amplify/storage/resource.ts` for folder access
- â¬œ Update `amplify/backend.ts` to include function

### Frontend Updates
- â¬œ Create ProgressiveImageLoader component
  - â¬œ Load thumbnail first
  - â¬œ Load compressed image progressively
  - â¬œ Add "View Original" option
  - â¬œ Show loading progress
- â¬œ Update ImageViewer to use ProgressiveImageLoader
- â¬œ Display compression statistics in image metadata
- â¬œ Use thumbnails in gallery for performance

### Settings Page
- â¬œ Create Settings page layout
- â¬œ Implement BedrockModelConfiguration panel
  - â¬œ Model selection dropdown
  - â¬œ Default language selection
  - â¬œ Parameter tuning (temperature, max tokens)
- â¬œ Save settings to user preferences (DynamoDB)

**Sprint 4 Acceptance Criteria:**
- âœ… Users can select language when uploading images
- âœ… Images can be filtered by language
- âœ… Bedrock prompts use appropriate language
- âœ… Multiple Bedrock models are supported
- âœ… Images are automatically compressed on upload
- âœ… Thumbnails are generated for gallery view
- âœ… Progressive image loading works
- âœ… Settings page allows model configuration

---

## Sprint 5: Mobile Optimization & Camera Capture

**Goal**: First-class mobile experience with camera capture
**Duration**: 2 weeks
**Deliverable**: Mobile-optimized annotation and camera integration

### Camera Capture UI
- â¬œ Create CameraCapture component
  - â¬œ Implement HTML5 camera access
    ```html
    <input type="file" accept="image/*" capture="camera" />
    ```
  - â¬œ Add camera permission handling
  - â¬œ Support front/back camera switching
  - â¬œ Show live camera preview
  - â¬œ Implement photo capture
  - â¬œ Add photo preview before upload
  - â¬œ Integrate with existing upload flow
- â¬œ Add camera capture option to Upload page
- â¬œ Test camera on iOS and Android browsers

### Mobile-Optimized Annotation UI
- â¬œ Create TouchAnnotator component (mobile version)
  - â¬œ Touch-friendly bounding box creation
  - â¬œ Pinch-to-zoom gesture support
  - â¬œ Two-finger pan gesture
  - â¬œ Large touch targets (44x44px minimum)
  - â¬œ Corner handles for resizing (12px+ touch area)
  - â¬œ Tap to select box
  - â¬œ Long-press for context menu
  - â¬œ Optional: Haptic feedback
- â¬œ Implement mobile-specific controls
  - â¬œ Touch-friendly validation buttons (44x44px)
  - â¬œ Bottom sheet for annotation form
  - â¬œ Mobile-optimized keyboard for text input
- â¬œ Add orientation support (portrait and landscape)

### Responsive Design
- â¬œ Audit all pages for mobile responsiveness
- â¬œ Implement mobile-first CSS
  - â¬œ Mobile (375px - 767px)
  - â¬œ Tablet (768px - 1023px)
  - â¬œ Desktop (1024px+)
- â¬œ Update navigation for mobile (hamburger menu)
- â¬œ Optimize dashboard for mobile layout
- â¬œ Test on various device sizes

### Performance Optimization for Mobile
- â¬œ Implement lazy loading for images
- â¬œ Add service worker for offline support (optional)
- â¬œ Optimize bundle size
  ```bash
  npm install --save-dev webpack-bundle-analyzer
  ```
- â¬œ Test on 3G/4G networks (throttling)
- â¬œ Measure page load times on mobile devices

### Common Components
- â¬œ Create NotificationToast component
- â¬œ Implement LoadingSpinner
- â¬œ Create ErrorBoundary
- â¬œ Implement ConfirmDialog (mobile-friendly)
- â¬œ Create Tooltip component
- â¬œ Implement ProgressBar

**Sprint 5 Acceptance Criteria:**
- âœ… Users can capture photos with device camera
- âœ… Camera works on iOS and Android browsers
- âœ… Touch annotation works smoothly on mobile
- âœ… Pinch-to-zoom and pan gestures work
- âœ… All pages are responsive and mobile-friendly
- âœ… App performs well on mobile networks
- âœ… Portrait and landscape orientations supported

---

## Sprint 6: Dataset Publishing & PII Handling

**Goal**: Publish datasets to Hugging Face with PII redaction
**Duration**: 2 weeks
**Deliverable**: One-click dataset publishing with compliance

### Advanced Export Formats
- â¬œ Extend export Lambda to support multiple formats
  - â¬œ JSON (existing)
  - â¬œ JSONL (streaming format)
  - â¬œ Parquet (for HuggingFace)
- â¬œ Install Apache Arrow for Parquet export
  ```bash
  cd amplify/functions/export-dataset
  npm install apache-arrow parquetjs
  ```
- â¬œ Implement Parquet export formatter
  - â¬œ Design Parquet schema for nested structures
  - â¬œ Optimize row group size
  - â¬œ Add compression (Snappy)
  - â¬œ Validate output
- â¬œ Add bounding box normalization utilities
  - â¬œ Convert absolute pixels to 0-1 normalized
  - â¬œ Convert to 0-1000 (LayoutLM standard)
  - â¬œ Support both formats in export
- â¬œ Update ExportDialog to support all formats

### PII Detection & Redaction
- â¬œ Create `amplify/functions/pii-redactor/` directory
- â¬œ Create `amplify/functions/pii-redactor/resource.ts`
- â¬œ Implement PIIDetector service (multi-language)
  - â¬œ Japanese patterns (phone, names, addresses)
  - â¬œ English patterns (SSN, phone, emails)
  - â¬œ Chinese patterns (ID numbers, phone)
  - â¬œ Korean patterns (phone, names)
  - â¬œ Universal patterns (emails, credit cards)
- â¬œ Implement image redaction using Sharp
  - â¬œ Blur detected PII regions (Gaussian blur)
  - â¬œ Preserve quality outside redacted areas
  - â¬œ Generate redacted image version
- â¬œ Implement text redaction in annotations
  - â¬œ Replace PII with placeholders
  - â¬œ Log redaction actions for audit
- â¬œ Add PII scanning to dataset export process
- â¬œ Update `amplify/backend.ts` to include function

### PII Detection UI
- â¬œ Create PIIRedactionControls component
  - â¬œ "Scan for PII" button
  - â¬œ Display PII detection results with confidence
  - â¬œ Allow manual review and override
  - â¬œ Show redaction progress
- â¬œ Add PII handling options to ExportDialog
  - â¬œ Include (no redaction)
  - â¬œ Redact (blur images, replace text)
  - â¬œ Exclude (remove PII annotations)
- â¬œ Display PII warnings before export

### Hugging Face Integration
- â¬œ Create `amplify/functions/hf-publisher/` directory
- â¬œ Create `amplify/functions/hf-publisher/resource.ts`
- â¬œ Install Hugging Face Hub SDK
  ```bash
  npm install @huggingface/hub
  ```
- â¬œ Implement HuggingFace client
  - â¬œ Create dataset repository
  - â¬œ Upload Parquet files
  - â¬œ Generate dataset card (README.md)
    - â¬œ Multi-language dataset description
    - â¬œ Citation (BibTeX and APA)
    - â¬œ Licensing (CC BY-SA 4.0)
    - â¬œ Usage examples with datasets library
    - â¬œ Language distribution statistics
    - â¬œ Legal context for international users
  - â¬œ Add version tagging
  - â¬œ Store HF dataset URL in DynamoDB
- â¬œ Add HF API token management to Settings
- â¬œ Update `amplify/backend.ts` to include function

### Publishing UI
- â¬œ Add "Publish to Hugging Face" button to DatasetDetails
- â¬œ Create PublishDialog component
  - â¬œ HuggingFace organization selection
  - â¬œ Dataset name and description
  - â¬œ License selection
  - â¬œ PII handling options
  - â¬œ Language filter
  - â¬œ Preview dataset card
- â¬œ Implement publish workflow
- â¬œ Display publication status and HF URL
- â¬œ Handle API rate limits and errors

### Dataset Card Template
- â¬œ Create dataset card template
- â¬œ Include standard sections
  - â¬œ Dataset Description
  - â¬œ Dataset Structure
  - â¬œ Multi-language support
  - â¬œ Citation format
  - â¬œ PII handling procedures
  - â¬œ Usage examples
  - â¬œ Legal context

**Sprint 6 Acceptance Criteria:**
- âœ… Datasets can be exported in JSON, JSONL, Parquet
- âœ… Bounding box normalization works correctly
- âœ… PII detection identifies sensitive data
- âœ… PII can be redacted from images and text
- âœ… Datasets can be published to Hugging Face
- âœ… Dataset card is auto-generated
- âœ… Publication URL is stored and displayed

---

## Sprint 7: Production Readiness & Polish

**Goal**: Production-ready secure and monitored platform
**Duration**: 2 weeks
**Deliverable**: Secure, documented, monitored system

### Security Hardening
- â¬œ Implement input validation on all forms
- â¬œ Sanitize user inputs (prevent XSS)
- â¬œ Implement CSRF protection
- â¬œ Set up Content Security Policy headers
- â¬œ Enable HTTPS only (HSTS)
- â¬œ Review S3 bucket policies (least privilege)
- â¬œ Review IAM roles and policies
- â¬œ Enable AWS CloudTrail for audit logs
- â¬œ Set up AWS Config for compliance
- â¬œ Secure API keys in AWS Secrets Manager
  ```bash
  aws secretsmanager create-secret --name hf-api-token
  ```
- â¬œ Implement presigned URL expiration (1 hour)
- â¬œ Enable DynamoDB encryption at rest (verify)
- â¬œ Enable S3 encryption at rest (verify)

### Vulnerability Scanning
- â¬œ Set up npm audit
  ```bash
  npm audit
  ```
- â¬œ Integrate Snyk for security scanning
  ```bash
  npm install -g snyk
  snyk test
  ```
- â¬œ Fix identified vulnerabilities
- â¬œ Schedule regular security audits

### Monitoring & Logging
- â¬œ Set up CloudWatch dashboards
  - â¬œ Lambda error rates
  - â¬œ API latency
  - â¬œ Bedrock API failures
  - â¬œ Storage usage
  - â¬œ DynamoDB read/write capacity
- â¬œ Configure CloudWatch alarms
  - â¬œ High error rates (email notification)
  - â¬œ High latency (>3s)
  - â¬œ Storage nearing quota
- â¬œ Implement structured logging in Lambda functions
  ```typescript
  import { Logger } from '@aws-lambda-powertools/logger';
  const logger = new Logger();
  ```
- â¬œ Set up log aggregation (CloudWatch Insights)
- â¬œ Configure SNS notifications for critical alarms
  ```bash
  aws sns create-topic --name amplify-alerts
  ```

### Error Tracking
- â¬œ Integrate frontend error tracking (Sentry or Rollbar)
  ```bash
  npm install @sentry/react
  ```
- â¬œ Configure error reporting for Lambda functions
- â¬œ Set up error alert notifications
- â¬œ Create error triage workflow

### Performance Monitoring
- â¬œ Implement APM (Application Performance Monitoring)
- â¬œ Set up X-Ray tracing for Lambda functions
  ```typescript
  import { captureLambdaHandler } from '@aws-lambda-powertools/tracer';
  ```
- â¬œ Monitor database query performance
- â¬œ Monitor Bedrock API latency
- â¬œ Create performance optimization plan

### Backup & Recovery
- â¬œ Enable DynamoDB point-in-time recovery
  ```bash
  aws dynamodb update-continuous-backups \
    --table-name Image \
    --point-in-time-recovery-specification PointInTimeRecoveryEnabled=true
  ```
- â¬œ Enable S3 versioning for critical buckets
- â¬œ Create disaster recovery plan document
- â¬œ Document recovery procedures
- â¬œ Test backup restoration process

### Testing
- â¬œ Set up Jest testing framework
  ```bash
  npm install --save-dev jest @types/jest ts-jest
  ```
- â¬œ Write unit tests for utility functions
  - â¬œ Bounding box normalization
  - â¬œ PII detection patterns
  - â¬œ Image compression logic
- â¬œ Write tests for React components
  ```bash
  npm install --save-dev @testing-library/react
  ```
- â¬œ Write integration tests for Lambda functions
- â¬œ Set up E2E testing with Cypress/Playwright
  ```bash
  npm install --save-dev @playwright/test
  ```
- â¬œ Write E2E test for annotation workflow
- â¬œ Test across browsers (Chrome, Safari, Firefox)
- â¬œ Test responsive design on devices
- â¬œ Achieve >80% code coverage

### Performance Testing
- â¬œ Load test image upload (concurrent users)
- â¬œ Load test annotation generation
- â¬œ Test compression with various image sizes
- â¬œ Test on simulated mobile networks
- â¬œ Optimize slow queries and operations

### Documentation
- â¬œ Create user guide for curators
- â¬œ Create user guide for annotators
- â¬œ Document API endpoints
- â¬œ Create architecture diagrams
  ```bash
  npm install --save-dev mermaid
  ```
- â¬œ Document deployment process
- â¬œ Create troubleshooting guide
- â¬œ Document Bedrock integration
- â¬œ Create video tutorials (optional)

### CI/CD Pipeline
- â¬œ Set up GitHub Actions workflow
  ```yaml
  # .github/workflows/deploy.yml
  name: Deploy to Amplify
  on: [push]
  jobs:
    deploy:
      runs-on: ubuntu-latest
      steps:
        - uses: actions/checkout@v3
        - run: npm ci
        - run: npm test
        - run: npx ampx pipeline-deploy
  ```
- â¬œ Configure automated testing on PR
- â¬œ Set up staging environment
- â¬œ Configure production deployment
- â¬œ Add deployment approval workflow

### Launch Preparation
- â¬œ Complete security review checklist
- â¬œ Complete performance testing
- â¬œ Verify all monitoring is active
- â¬œ Create launch plan document
- â¬œ Prepare rollback plan
- â¬œ Train initial users
- â¬œ Set up support channels (email, chat)
- â¬œ Prepare announcement (blog post, social media)

**Sprint 7 Acceptance Criteria:**
- âœ… Security scan passes with no critical issues
- âœ… All monitoring dashboards are active
- âœ… Error tracking is configured
- âœ… Backup and recovery tested
- âœ… Test coverage >80%
- âœ… Documentation is complete
- âœ… CI/CD pipeline is operational
- âœ… Ready for production launch

---

## Post-Launch: Maintenance & Enhancements

### Launch Activities
- â¬œ Deploy to production
  ```bash
  npx ampx pipeline-deploy --branch main
  ```
- â¬œ Monitor for issues (first 48 hours)
- â¬œ Collect initial user feedback
- â¬œ Address critical issues immediately
- â¬œ Publish announcement
- â¬œ Conduct retrospective meeting

### Post-Launch Optimization
- â¬œ Analyze user behavior with analytics
- â¬œ Identify bottlenecks and optimize
- â¬œ Gather feature requests
- â¬œ Prioritize roadmap
- â¬œ Plan next sprint

---

## Future Enhancements (Backlog)

### Advanced Features
- â¬œ Multi-annotator consensus workflow
- â¬œ Real-time collaboration on annotations
- â¬œ Advanced analytics dashboard with ML insights
- â¬œ Custom model training pipeline
- â¬œ Native mobile app (React Native)
- â¬œ Public API for programmatic access
- â¬œ Webhook integrations
- â¬œ Annotation templates and presets
- â¬œ Bulk operations (batch approve/delete)
- â¬œ Dataset versioning with diff view
- â¬œ Annotation quality scoring

### Additional Integrations
- â¬œ Integration with Label Studio
- â¬œ Integration with CVAT
- â¬œ Support for GPT-4V model
- â¬œ Export to COCO format
- â¬œ Export to Pascal VOC format
- â¬œ Integration with Labelbox
- â¬œ IIIF (International Image Interoperability Framework) support

### Infrastructure Enhancements
- â¬œ Multi-region deployment
- â¬œ CDN for global performance (CloudFront)
- â¬œ Redis caching layer for API responses
- â¬œ Dataset partitioning for large collections
- â¬œ Database migration to Aurora (if needed)
- â¬œ Implement search with OpenSearch

### Advanced AI Features
- â¬œ Support for additional Bedrock models
- â¬œ Custom prompt engineering interface
- â¬œ Active learning to improve annotation quality
- â¬œ Automated quality assessment
- â¬œ Confidence scoring for annotations

---

## Amplify Gen2 Command Reference

### Development Commands
```bash
# Initialize new Amplify project
npm create amplify@latest

# Install Amplify dependencies
npm install aws-amplify @aws-amplify/ui-react
npm install --save-dev @aws-amplify/backend @aws-amplify/backend-cli

# Start local sandbox (with hot reload)
npx ampx sandbox

# Stream function logs while in sandbox
npx ampx sandbox --stream-function-logs

# Filter logs from specific functions
npx ampx sandbox --logs-filter "generateAnnotation"

# Generate GraphQL client types
npx ampx generate graphql-client-code

# Delete sandbox
npx ampx sandbox delete
```

### Deployment Commands
```bash
# Deploy to Amplify (production)
npx ampx pipeline-deploy --branch main

# Deploy to staging
npx ampx pipeline-deploy --branch staging

# Check deployment status
aws amplify list-apps
```

### AWS Configuration
```bash
# Configure AWS credentials
aws configure

# Create secrets for sensitive data
aws secretsmanager create-secret --name hf-api-token --secret-string "your-token"

# Enable Bedrock model access (via AWS Console)
# Navigate to: Amazon Bedrock > Model access > Request model access
```

### Testing Commands
```bash
# Run unit tests
npm test

# Run E2E tests
npx playwright test

# Security audit
npm audit
snyk test

# Bundle analysis
npm run build
npx webpack-bundle-analyzer build/stats.json
```

---

## Amplify Gen2 File Structure

```
business-ocr-annotator/
â”œâ”€â”€ amplify/
â”‚   â”œâ”€â”€ auth/
â”‚   â”‚   â””â”€â”€ resource.ts           # defineAuth()
â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â””â”€â”€ resource.ts           # defineStorage()
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ resource.ts           # defineData() with schema
â”‚   â”œâ”€â”€ functions/
â”‚   â”‚   â”œâ”€â”€ generate-annotation/
â”‚   â”‚   â”‚   â”œâ”€â”€ resource.ts       # defineFunction()
â”‚   â”‚   â”‚   â”œâ”€â”€ handler.ts        # Lambda handler
â”‚   â”‚   â”‚   â””â”€â”€ package.json
â”‚   â”‚   â”œâ”€â”€ export-dataset/
â”‚   â”‚   â”‚   â”œâ”€â”€ resource.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ handler.ts
â”‚   â”‚   â”‚   â””â”€â”€ package.json
â”‚   â”‚   â”œâ”€â”€ image-processor/
â”‚   â”‚   â”‚   â”œâ”€â”€ resource.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ handler.ts
â”‚   â”‚   â”‚   â””â”€â”€ package.json
â”‚   â”‚   â”œâ”€â”€ pii-redactor/
â”‚   â”‚   â”‚   â”œâ”€â”€ resource.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ handler.ts
â”‚   â”‚   â”‚   â””â”€â”€ package.json
â”‚   â”‚   â””â”€â”€ hf-publisher/
â”‚   â”‚       â”œâ”€â”€ resource.ts
â”‚   â”‚       â”œâ”€â”€ handler.ts
â”‚   â”‚       â””â”€â”€ package.json
â”‚   â””â”€â”€ backend.ts                # defineBackend() - imports all resources
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ App.tsx
â”‚   â””â”€â”€ main.tsx                  # Vite entry point
â”œâ”€â”€ public/                       # Static assets
â”œâ”€â”€ index.html                    # HTML entry point (Vite)
â”œâ”€â”€ amplify_outputs.json          # Generated after deployment
â”œâ”€â”€ vite.config.ts                # Vite configuration
â”œâ”€â”€ package.json
â””â”€â”€ tsconfig.json
```

---

## Risk Management

### Known Risks
1. **Bedrock Model Availability**: Dependency on external model API
   - Mitigation: Multiple model options, robust error handling

2. **Hugging Face API Limits**: Rate limiting and quotas
   - Mitigation: Retry logic, batch operations, upgrade plan if needed

3. **Dataset Size**: Large datasets may impact performance
   - Mitigation: Pagination, lazy loading, partitioning

4. **Annotation Quality**: AI-generated annotations may have errors
   - Mitigation: Human validation workflow, confidence thresholds

5. **Cost Overruns**: AWS and Bedrock costs may exceed budget
   - Mitigation: Monitor costs, implement limits, optimize storage

6. **Mobile Browser Compatibility**: Camera API may vary across devices
   - Mitigation: Fallback mechanisms, progressive enhancement, testing

---

## Progress Tracking

**Last Review Date**: 2026-01-11
**Next Review Date**: TBD
**Completed Tasks**: Sprint 0 + Sprint 1 completed
**Current Sprint**: Sprint 2 (AI-Assisted Annotation)

### Sprint Completion Status
- âœ… Sprint 0: Foundation & Deployment
- âœ… Sprint 1: Image Upload & Manual Annotation (MVP)
- â¬œ Sprint 2: AI-Assisted Annotation
- â¬œ Sprint 3: Dataset Management, Export & Validation (with W&B)
- â¬œ Sprint 4: Multi-Language Support & Optimization
- â¬œ Sprint 5: Mobile Optimization & Camera
- â¬œ Sprint 6: Publishing & PII Handling
- â¬œ Sprint 7: Production Readiness

---

## Notes

- **Agile Approach**: Each sprint delivers working, deployable software
- **User Feedback**: Collect feedback after Sprints 1, 2, and 3
- **Incremental Complexity**: Start simple, add features gradually
- **Integration**: Frontend and backend tasks are integrated per sprint
- **Flexibility**: Sprint order can be adjusted based on priorities
- **Documentation**: Update this file after each sprint completion
- **Proposals**: Create proposal documents for significant changes

---

## Sources & References

- [AWS Amplify Gen2 Documentation](https://docs.amplify.aws/)
- [CLI Commands Reference](https://docs.amplify.aws/react/reference/cli-commands/)
- [Sandbox Features](https://docs.amplify.aws/react/deploy-and-host/sandbox-environments/features/)
- [create-amplify npm package](https://www.npmjs.com/package/create-amplify)
- [Amplify Storage with TypeScript](https://aws.amazon.com/blogs/mobile/amplify-storage-now-with-fullstack-typescript-powered-by-amazon-s3/)
