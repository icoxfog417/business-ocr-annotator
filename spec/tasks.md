# Implementation Tasks

**Project**: Business OCR Annotator
**Last Updated**: 2026-01-25
**Status**: Sprint 3 Complete, Starting Sprint 4 (Dataset Export & Evaluation)
**Approach**: Agile Incremental Development
**Reference**: See [spec/proposals/20260107_reorganize_tasks_agile_approach.md](proposals/20260107_reorganize_tasks_agile_approach.md)

## Task Status Legend

- â¬œ **TODO**: Not started
- ğŸ”„ **IN PROGRESS**: Currently being worked on
- âœ… **DONE**: Completed
- ğŸš« **BLOCKED**: Waiting on dependencies or external factors
- â¸ï¸ **ON HOLD**: Paused temporarily

---

## Agile Development Approach

This task list is organized into **sprints** that deliver working software incrementally. Each sprint includes both frontend and backend tasks necessary to deliver a complete, deployable feature.

**Key Principles:**
- Each sprint delivers a working, deployable application
- Frontend and backend tasks are integrated within each sprint
- User feedback is collected after key sprints (1, 2, 3)
- Infrastructure is built incrementally as needed for features
- Complexity is added gradually based on validated learning

---

## Sprint 0: Foundation & Deployment

**Goal**: Deploy a working authenticated "Hello World" app to AWS
**Duration**: 1-2 weeks
**Deliverable**: Users can log in and see an empty dashboard

### Project Initialization
- âœ… Create React app with Vite and TypeScript
  ```bash
  # Create Vite project (this downloads create-vite temporarily via npx)
  npm create vite@latest business-ocr-annotator -- --template react-ts

  # Enter project directory
  cd business-ocr-annotator

  # Install base dependencies (React, Vite, TypeScript, etc.)
  npm install
  ```

- âœ… Initialize Amplify Gen2 project
  ```bash
  # Add Amplify to existing project (run from project root)
  npm create amplify@latest
  ```
  This creates the `amplify/` directory structure:
  - `amplify/auth/resource.ts`
  - `amplify/data/resource.ts`
  - `amplify/backend.ts`

### Development Environment Setup
- âœ… Install essential dependencies only
  ```bash
  # Install Amplify client libraries (REQUIRED)
  npm install aws-amplify @aws-amplify/ui-react

  # Install Amplify backend development tools (REQUIRED)
  npm install --save-dev @aws-amplify/backend @aws-amplify/backend-cli

  # Install React Router for navigation (REQUIRED)
  npm install react-router-dom

  # Install linting and formatting tools for code quality (REQUIRED)
  npm install --save-dev eslint @typescript-eslint/parser @typescript-eslint/eslint-plugin
  npm install --save-dev prettier eslint-config-prettier eslint-plugin-react-hooks

  # Install git hooks for automated quality checks (REQUIRED)
  npm install --save-dev husky lint-staged
  ```

- âœ… Create ESLint configuration `eslint.config.js`
  ```javascript
  module.exports = {
    root: true,
    env: { browser: true, es2020: true },
    extends: [
      'eslint:recommended',
      'plugin:@typescript-eslint/recommended',
      'plugin:react-hooks/recommended',
      'prettier'
    ],
    ignorePatterns: ['dist', '.eslintrc.cjs', 'amplify_outputs.json'],
    parser: '@typescript-eslint/parser',
    plugins: ['react-hooks'],
  };
  ```

- âœ… Create Prettier configuration `.prettierrc`
  ```json
  {
    "semi": true,
    "trailingComma": "es5",
    "singleQuote": true,
    "printWidth": 100,
    "tabWidth": 2
  }
  ```

- âœ… Add lint scripts to `package.json`
  ```json
  {
    "scripts": {
      "lint": "eslint . --ext ts,tsx --report-unused-disable-directives --max-warnings 0",
      "format": "prettier --write \"src/**/*.{ts,tsx,css}\""
    }
  }
  ```

- âœ… Set up Husky for git hooks
  ```bash
  npx husky init
  echo "npm run lint-staged" > .husky/pre-commit
  ```

- âœ… Configure lint-staged in `package.json`
  ```json
  {
    "lint-staged": {
      "*.{ts,tsx}": [
        "prettier --write",
        "eslint --fix"
      ],
      "*.{css,json,md}": [
        "prettier --write"
      ]
    }
  }
  ```

**Note**: Git hooks automatically run linting and formatting before each commit to maintain code quality.

### Authentication Setup (Amplify Gen2)
- âœ… Set up Google OAuth credentials
  - Go to [Google Cloud Console](https://console.cloud.google.com/)
  - Create a new project or use existing one
  - Enable Google+ API
  - Create OAuth 2.0 credentials (OAuth client ID)
  - Add authorized redirect URIs (Amplify will provide these)
  - Save Client ID and Client Secret

- âœ… Configure Google OAuth in `amplify/auth/resource.ts`
  ```typescript
  import { defineAuth } from '@aws-amplify/backend';

  export const auth = defineAuth({
    loginWith: {
      externalProviders: {
        google: {
          clientId: process.env.GOOGLE_CLIENT_ID!,
          clientSecret: process.env.GOOGLE_CLIENT_SECRET!,
        },
        callbackUrls: [
          'http://localhost:5173',  // Vite dev server
          'https://your-app-domain.amplifyapp.com'  // Production
        ],
        logoutUrls: [
          'http://localhost:5173',
          'https://your-app-domain.amplifyapp.com'
        ]
      }
    }
  });
  ```

- âœ… Add Google credentials to environment
  ```bash
  # For local development
  npx ampx sandbox secret set GOOGLE_CLIENT_ID
  npx ampx sandbox secret set GOOGLE_CLIENT_SECRET
  ```
- âœ… Update `amplify/backend.ts` to include auth
  ```typescript
  import { defineBackend } from '@aws-amplify/backend';
  import { auth } from './auth/resource';

  defineBackend({
    auth
  });
  ```
- âœ… Configure Amplify client in frontend
  ```typescript
  // In src/main.tsx
  import { Amplify } from 'aws-amplify';
  import outputs from '../amplify_outputs.json';

  Amplify.configure(outputs);
  ```

- âœ… Add Google OAuth sign-in to App.tsx
  ```typescript
  import { Authenticator } from '@aws-amplify/ui-react';
  import '@aws-amplify/ui-react/styles.css';

  // The Authenticator will automatically show Google sign-in button
  function App() {
    return (
      <Authenticator socialProviders={['google']}>
        {({ signOut, user }) => (
          <main>
            <h1>Hello {user?.username}</h1>
            <button onClick={signOut}>Sign out</button>
          </main>
        )}
      </Authenticator>
    );
  }
  ```

### Basic Frontend Structure
- âœ… Create main layout component with navigation
- âœ… Create empty Dashboard page
- âœ… Set up React Router v6 (already installed above)
- âœ… Implement authenticated routing wrapper
- âœ… Add logout functionality

### Deployment & Testing
- âœ… Start local sandbox environment
  ```bash
  npx ampx sandbox
  ```
- âœ… Test authentication flow locally
- âœ… Configure AWS credentials
  ```bash
  aws configure
  ```
- âœ… Deploy to Amplify Hosting
- âœ… Verify authentication works in deployed app

### Documentation
- âœ… Create README.md
- âœ… Create CLAUDE.md for agent workflow
- âœ… Create spec/requirements.md
- âœ… Create spec/design.md
- âœ… Create spec/tasks.md
- â¬œ Create CONTRIBUTING.md
- â¬œ Create LICENSE file
- â¬œ Document Sprint 0 setup process

**Sprint 0 Acceptance Criteria:**
- âœ… App deployed to AWS Amplify
- âœ… Users can sign in with Google account
- âœ… Users can log out
- âœ… Authenticated users see a dashboard (even if empty)
- âœ… Sandbox environment working locally
- âœ… Google OAuth credentials configured securely

---

## Sprint 1: Image Upload & Manual Annotation (MVP) - âœ… COMPLETED

**Goal**: Upload images and create annotations manually (no AI yet)
**Duration**: 2-3 weeks
**Deliverable**: Working annotation tool with manual Q&A entry

### Storage Setup (Amplify Gen2)
- âœ… Create `amplify/storage/resource.ts`
- âœ… Update `amplify/backend.ts` to include storage
- âœ… Test S3 upload functionality in sandbox

### Data Model Setup (Amplify Gen2)
- âœ… Define minimal data schema in `amplify/data/resource.ts`
- âœ… Add Image and Annotation models with relationships
- âœ… Update `amplify/backend.ts` to include data
- âœ… Generate GraphQL client types
- âœ… Test data operations in sandbox

### Image Upload UI
- âœ… Create FileUpload page with native drag-and-drop
- âœ… Implement file validation (type, size â‰¤20MB)
- âœ… Add image preview before upload using FileReader API
- âœ… Implement S3 upload using Amplify Storage
- âœ… Save image metadata to DynamoDB via GraphQL
- âœ… Show upload progress indicator
- âœ… Handle upload errors with retry option

### Image Gallery UI
- âœ… Create ImageGallery page
- âœ… Implement image grid with lazy loading
- âœ… Fetch images from GraphQL API
- âœ… Display image thumbnails using S3 presigned URLs
- âœ… Add click to open annotation workspace
- âœ… Implement basic filtering (date, uploaded by)
- âœ… Add image deletion functionality

### Manual Annotation Workspace
- âœ… Create AnnotationWorkspace page with layout
- âœ… Implement ImageViewer component
  - âœ… Display full-size image from S3
  - âœ… Add zoom controls (zoom in, out, reset, fit)
  - âœ… Implement pan functionality
- âœ… Create CanvasAnnotator for bounding boxes
  - âœ… Render image with HTML5 canvas overlay
  - âœ… Implement drag-to-create bounding box
  - âœ… Implement box selection (click to select)
  - âœ… Add delete box functionality
  - âœ… Store coordinates in pixels {x, y, width, height}
- âœ… Create AnnotationForm component
  - âœ… QuestionInput text field
  - âœ… AnswerInput text field
  - âœ… Associate annotation with selected bounding box
  - âœ… Display bounding box coordinates
- âœ… Create AnnotationList component
  - âœ… Display all annotations for current image
  - âœ… Click annotation to highlight its bounding box
  - âœ… Edit/delete existing annotations
- âœ… Implement save functionality (save to DynamoDB via GraphQL)

### Dashboard Updates
- âœ… Display total images count
- âœ… Display total annotations count
- âœ… Show recent uploads list
- âœ… Add navigation to Upload and Gallery pages

**Sprint 1 Acceptance Criteria:**
- âœ… Users can upload images (single or batch)
- âœ… Uploaded images appear in gallery
- âœ… Users can open annotation workspace
- âœ… Users can draw bounding boxes on images
- âœ… Users can manually enter questions and answers
- âœ… Annotations are saved and persisted
- âœ… Users can view, edit, and delete annotations
- âœ… Dashboard shows basic statistics
- âœ… Zoom and pan controls work in annotation workspace
- âœ… GraphQL types are generated and working
- âœ… Sandbox deployment is successful

---

## Sprint 2: AI-Assisted Annotation (Nemotron Integration) - âœ… COMPLETED

**Goal**: Auto-generate annotations using NVIDIA Nemotron Nano 12B
**Duration**: 2-3 weeks
**Deliverable**: One-click AI annotation generation

### Nemotron Setup
- âœ… Research NVIDIA Nemotron Nano 12B deployment options
- âœ… Set up Nemotron model endpoint (via Amazon Bedrock)
- âœ… Configure IAM permissions for Bedrock access
- â¬œ Test model inference with sample images

### Lambda Function for Annotation Generation
- âœ… Create `amplify/functions/generate-annotation/` directory
- âœ… Create `amplify/functions/generate-annotation/resource.ts`
- âœ… Implement handler in `amplify/functions/generate-annotation/handler.ts`
- âœ… Implement Bedrock Converse API integration
  - âœ… Initialize Bedrock client
  - âœ… Create prompt templates for multiple languages (ja, en, zh, ko)
  - âœ… Implement API call with image from S3
  - âœ… Parse response to extract Q&A pairs and bounding boxes
- âœ… Add Lambda environment variables (MODEL_ID, STORAGE_BUCKET_NAME)
- âœ… Grant Lambda permissions to access S3 and Bedrock
- âœ… Store generated annotations in DynamoDB (done via frontend)
- âœ… Add error handling and retry logic
- âœ… Implement CloudWatch logging

### Update Backend Configuration
- âœ… Update `amplify/backend.ts` to include function
- âœ… Add GraphQL custom query/mutation for annotation generation
- âœ… Test Lambda function in sandbox
  ```bash
  npx ampx sandbox --stream-function-logs
  ```

### Default Questions Configuration
- âœ… Add DefaultQuestion model to `amplify/data/resource.ts`
- âœ… Create DefaultQuestionManager admin page (basic fallback implementation)
- âœ… Seed initial default questions for each document type and language (fallback questions)

### Annotation Workflow UI
- âœ… Update AnnotationWorkspace with AI suggestion panel
- âœ… Implement QuestionList with default questions loading
- âœ… Implement AISuggestionList with adopt/reject buttons
- âœ… Implement AnswerEditor with AI suggestion button
- âœ… Implement FinalizeControls with finalize/re-open buttons
- âœ… Add question status indicators (pending/answered)

### Frontend Integration
- âœ… Add "Generate Annotations" button to AnnotationWorkspace
- âœ… Implement API call to Lambda function (with mock fallback)
- âœ… Show loading state during generation (with spinner)
- âœ… Display generated annotations in AISuggestionList
- âœ… Allow users to edit/approve/reject AI annotations
- âœ… Add confidence score display
- âœ… Highlight AI-generated vs manual annotations
- âœ… Handle generation errors gracefully

### Annotation Validation UI
- âœ… Create ValidationControls component (inline in AnnotationWorkspace)
  - âœ… Approve button (green checkmark)
  - âœ… Reject button (orange X)
  - âœ… Delete button
- âœ… Track annotation status (pending, approved, rejected)
- âœ… Update data model to include status field (generatedBy, modelVersion, confidence)
- âœ… Filter annotations by status in AnnotationList

### Contribution Tracking
- âœ… Add ContributionStats component to Dashboard
- âœ… Display AI vs Human annotation counts
- âœ… Display approved vs pending annotation counts

### Image Compression (Moved from Sprint 5)
**Proposal**: See [spec/proposals/20260111_move_compression_to_sprint2.md](proposals/20260111_move_compression_to_sprint2.md)

- âœ… Update data schema with 3-tier storage keys
  - âœ… Replace `s3Key` with `s3KeyOriginal`, `s3KeyCompressed`, `s3KeyThumbnail`
  - âœ… Add `originalSize`, `compressedSize`, `thumbnailSize` fields
  - âœ… Add `PROCESSING` status to ImageStatus enum
- âœ… Update storage structure for 3-tier folders
  - âœ… `images/original/*` - Original uploads
  - âœ… `images/compressed/*` - â‰¤4MB for AI processing
  - âœ… `images/thumbnail/*` - â‰¤100KB for gallery
- âœ… Create `amplify/functions/process-image/` directory
- âœ… Create `amplify/functions/process-image/resource.ts`
- âœ… Implement handler with Sharp library
  - âœ… Smart compression to â‰¤4MB target
  - âœ… Thumbnail generation â‰¤100KB
  - âœ… Upload to S3 compressed/ and thumbnail/ folders
  - âœ… Update Image record with new keys and sizes
- âœ… Update `amplify/backend.ts` with process-image function
- âœ… Update FileUpload page
  - âœ… Upload to `images/original/` folder
  - âœ… Set status to PROCESSING on upload
  - âœ… Show processing status
- âœ… Set up S3 event trigger for automatic processing
- âœ… Update ImageGallery to use thumbnail URLs
- âœ… Update AnnotationWorkspace to use compressed image URL

### Review Fixes (Post-Implementation)
**Review Document**: See [spec/proposals/20260111_sprint2_compression_review.md](proposals/20260111_sprint2_compression_review.md)

- âœ… P0: Replace DynamoDB Scan with Query using GSI on s3KeyOriginal
- âœ… P1: Fix status progression (PROCESSING â†’ ANNOTATING, not UPLOADED)
- âœ… P1: Add exponential backoff retry for eventual consistency
- âœ… P1: Increase Lambda timeout from 60s to 90s
- âœ… P2: Track compression ratio (originalSize / compressedSize)
- âœ… P2: Track original image format from Sharp metadata

**Sprint 2 Acceptance Criteria:**
- âœ… Users can click "Generate Annotations" button
- âœ… AI generates Q&A pairs with bounding boxes
- âœ… Generated annotations appear in the workspace
- âœ… Users can approve, reject, or edit AI annotations
- âœ… Annotation status is tracked and persisted
- âœ… Error handling works for AI model failures
- âœ… Images are compressed to 3-tier storage (original, compressed â‰¤4MB, thumbnail â‰¤100KB)
- âœ… Gallery uses thumbnails for fast loading
- âœ… Annotation workspace uses compressed images for AI processing

---

## Sprint 3: UX & Mobile UI Optimization

**Goal**: Streamlined annotation cycle + responsive mobile UI + legal compliance
**Duration**: 1 week (5-6 working days)
**Deliverable**: Optimized annotation workflow, mobile-friendly interface, user consent system
**Proposal**: See [spec/proposals/20260112_sprint3_mobile_first_ui.md](proposals/20260112_sprint3_mobile_first_ui.md)

### Parallel Work Units

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         SPRINT 3 PARALLEL EXECUTION                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  Day 1-2: Foundation (Run in Parallel)                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Unit A       â”‚  â”‚ Unit B       â”‚  â”‚ Unit C       â”‚  â”‚ Unit D       â”‚    â”‚
â”‚  â”‚ Backend      â”‚  â”‚ Config &     â”‚  â”‚ Layout       â”‚  â”‚ i18n &       â”‚    â”‚
â”‚  â”‚ Infrastructureâ”‚  â”‚ Hooks        â”‚  â”‚ Components   â”‚  â”‚ Styles       â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚         â”‚                 â”‚                 â”‚                 â”‚             â”‚
â”‚         â–¼                 â–¼                 â–¼                 â–¼             â”‚
â”‚  Day 3-4: Features (Run in Parallel, depends on Foundation)                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Unit E               â”‚  â”‚ Unit F               â”‚  â”‚ Unit G           â”‚  â”‚
â”‚  â”‚ Upload Flow          â”‚  â”‚ Annotation Flow      â”‚  â”‚ Mobile Features  â”‚  â”‚
â”‚  â”‚ (Consent + Questions)â”‚  â”‚ (Box-first + Read)   â”‚  â”‚ (Touch + Camera) â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚             â”‚                         â”‚                       â”‚             â”‚
â”‚             â–¼                         â–¼                       â–¼             â”‚
â”‚  Day 5-6: Integration & Testing                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Unit H: Page Integration + Testing                                   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Unit A: Backend Infrastructure âœ… COMPLETE

- âœ… Add Cognito custom attributes for consent in `amplify/auth/resource.ts`
  ```typescript
  userAttributes: {
    'custom:contributor': { dataType: 'String', mutable: true },
    'custom:consent_date': { dataType: 'String', mutable: true },
    'custom:consent_version': { dataType: 'String', mutable: true },
  }
  ```

- âœ… Update `Annotation` model in `amplify/data/resource.ts` with AI tracking fields
  - `aiAssisted: a.boolean()` - True if [ğŸ“– Read] was used
  - `aiModelId: a.string()` - Model ID (e.g., "anthropic.claude-3-5-sonnet")
  - `aiModelProvider: a.string()` - Provider (e.g., "bedrock")
  - `aiExtractionTimestamp: a.datetime()` - When AI extraction occurred

- âœ… Update `generate-annotation` Lambda to return model ID in response

---

### Unit B: Config & Hooks âœ… COMPLETE

- âœ… Create `src/config/defaultQuestions.json`
  - All document types (RECEIPT, INVOICE, ORDER_FORM, TAX_FORM, CONTRACT, APPLICATION_FORM, OTHER)
  - All languages (ja, en, zh, ko)
  - Default + optional questions per type/language

- âœ… Create `src/hooks/useDefaultQuestions.ts`
  - Load questions from JSON config
  - Filter by document type and language
  - Fallback to English if language not found

- âœ… Create `src/hooks/useContributorStatus.ts`
  - Check `custom:contributor` via `fetchUserAttributes()`
  - Update via `updateUserAttributes()` when accepted
  - Return `{ isContributor, isLoading, becomeContributor }`

- âœ… Create `src/contexts/ContributorContext.tsx`
  - Cache contributor status globally
  - Provide context to all components

- âœ… Create `src/hooks/useBreakpoint.ts`
  - Detect breakpoint: mobile (<768px), tablet (768-1024px), desktop (>1024px)
  - Return `{ isMobile, isTablet, isDesktop }`

- âœ… Create `src/hooks/useKeyboardShortcuts.ts`
  - Register/unregister keyboard event listeners
  - Support: `â†’`, `â†`, `D`, `R`, `S`, `Esc`, `Ctrl+Enter`

---

### Unit C: Layout Components âœ… COMPLETE

- âœ… Create `src/styles/breakpoints.css`
  ```css
  :root {
    --breakpoint-mobile: 768px;
    --breakpoint-tablet: 1024px;
  }
  ```

- âœ… Create `src/components/layout/ResponsiveContainer.tsx`
  - Wrapper that provides breakpoint context
  - Applies appropriate layout based on screen size

- âœ… Create `src/components/layout/StackedLayout.tsx`
  - Mobile-first vertical stacking
  - Full-width content areas

- âœ… Create `src/components/layout/SplitLayout.tsx`
  - Side-by-side layout for tablet/desktop
  - Configurable split ratio (e.g., 60/40)

- âœ… Create `src/components/layout/MobileNavigation.tsx`
  - Bottom navigation bar (60px + safe area)
  - Icons: Home, Upload, Gallery, Profile
  - Active state indicator
  - Hide on desktop

---

### Unit D: i18n & Styles âœ… COMPLETE

- âœ… Create `src/i18n/consent/en.json`
  ```json
  {
    "title": "Data Usage Consent",
    "message": "The images and Q&A you submit will be used to build a dataset...",
    "warning": "DO NOT submit personal or sensitive information.",
    "checkbox": "I understand and consent to the above terms",
    "cancel": "Cancel",
    "agree": "I Agree & Continue"
  }
  ```

- âœ… Create `src/i18n/consent/ja.json` (Japanese translation)

- âœ… Create `src/i18n/consent/zh.json` (Chinese translation)

- âœ… Create `src/i18n/consent/ko.json` (Korean translation - bonus)

- âœ… Create `src/styles/mobile.css`
  - Touch target minimum sizes (48px)
  - Mobile-specific spacing
  - Safe area padding for notched devices

---

### Unit E: Upload Flow âœ… COMPLETE

- âœ… Create `src/components/consent/StartContributingDialog.tsx`
  - Multi-language consent message (loads from i18n)
  - Checkbox for explicit consent
  - Cancel and Accept buttons
  - Calls `becomeContributor()` on accept

- âœ… Create `src/components/consent/ContributorGate.tsx`
  - Wrapper component for contributor-only actions
  - Shows dialog if not contributor
  - Passes through if contributor

- âœ… Create `src/components/upload/QuestionSelector.tsx`
  - Load questions via `useDefaultQuestions(docType, lang)`
  - Checkbox list with default questions pre-checked
  - Optional questions section
  - Custom question input field
  - Returns selected questions array

- âœ… Create `src/components/upload/CameraCapture.tsx`
  - HTML5 input with `capture="environment"`
  - Image preview before upload
  - "Take Photo" and "Choose from Gallery" options
  - Works on iOS Safari and Android Chrome

- âœ… Update `src/pages/FileUpload.tsx`
  - Wrap upload action with `ContributorGate`
  - Add `QuestionSelector` component
  - Add `CameraCapture` for mobile
  - Pass selected questions to annotation

---

### Unit F: Annotation Flow ğŸ”— (Depends on: Unit A, Unit B, Unit C)

- âœ… Create `src/components/annotation/ProgressDots.tsx`
  - Visual dots for question progress
  - States: pending (â—‹), current (â—), completed (âœ“)
  - Shows "3 of 5" text

- âœ… Create `src/components/annotation/QuestionNavigator.tsx`
  - Previous/Next buttons
  - Skip button
  - Progress dots
  - Current question display
  - Keyboard shortcut integration

- âœ… Create `src/components/annotation/ReadButton.tsx`
  - [ğŸ“– Read] button with loading state
  - Calls Bedrock Lambda with bounding box region
  - Extracts text and fills answer field
  - Captures model ID for tracking
  - Error handling with retry option
  - âœ… Improved prompt for value extraction (2026-01-25)
    - Extract value only (exclude labels like ç™»éŒ²ç•ªå·:, æ—¥ä»˜:)
    - Format: money â†’ numbers only, date â†’ yyyy/MM/dd, items â†’ one per line
    - See [spec/proposals/20260125_improve_read_button_prompt.md](proposals/20260125_improve_read_button_prompt.md)

- âœ… Create `src/components/annotation/FinalizeScreen.tsx`
  - Summary: X questions answered, Y boxes drawn
  - "Upload Next Image" primary button
  - "Back to Gallery" secondary button
  - Session stats (optional)

- âœ… Create `src/components/annotation/AnnotationFlow.tsx`
  - Container managing question-by-question flow
  - State: currentQuestionIndex, answers, boxes
  - Box-first workflow enforcement
  - Auto-advance on save
  - Integrates all annotation components
  - **Responsive layout: stacked (mobile) / side-by-side (desktop)**
  - **Keyboard shortcuts for desktop (â†â†’ navigate, D draw, S skip, Esc cancel)**

- âœ… Update `src/pages/AnnotationWorkspace.tsx`
  - Replace current layout with `AnnotationFlow`
  - Remove question add/remove during annotation
  - Add keyboard shortcut support
  - Responsive layout integration
  - **Load default questions from config when not passed via state**
  - **Unified UX for both desktop and mobile**
  - **Proposal**: See [spec/proposals/20260112_align_desktop_ux_with_mobile.md](proposals/20260112_align_desktop_ux_with_mobile.md)

---

### Unit G: Mobile Features âœ… COMPLETE

- âœ… Create `src/components/annotation/TouchCanvas.tsx`
  - Native touch events (touchstart, touchmove, touchend)
  - View mode: scroll/pan pass-through
  - Draw mode: single-finger box creation
  - Box selection by tap
  - Corner handles for resize (32Ã—32px touch area)
  - Visual feedback during interactions
  - **Move functionality**: drag inside box to reposition
  - **Resize functionality**: drag corners to resize
  - **Proposal**: See [spec/proposals/20260125_bounding_box_move_resize.md](proposals/20260125_bounding_box_move_resize.md)

- âœ… Create `src/components/annotation/ModeBadge.tsx`
  - Fixed position indicator (top-right)
  - Shows "VIEW" (gray) or "DRAW" (blue pulsing)
  - Tappable to toggle mode (48px touch area)

- âœ… Create `src/components/annotation/ZoomControls.tsx` (as ZoomControlsMobile.tsx)
  - [+] zoom in button
  - [âˆ’] zoom out button
  - [Fit] reset to fit view
  - Touch-friendly sizing (48Ã—48px each)

---

### Unit H: Integration & Testing ğŸ”— (Depends on: All Units)

**Page Updates:**
- âœ… Update `src/pages/Dashboard.tsx` for responsiveness
  - Card grid â†’ stacked on mobile
  - Add "Start Contributing" banner for non-contributors

- â¬œ Update `src/pages/ImageGallery.tsx` for responsiveness
  - Grid column adjustment by breakpoint (partial - uses inline window.innerWidth)
  - Touch-friendly image cards

- âœ… Integrate `MobileNavigation` in `src/App.tsx`
  - Show on mobile only
  - Hide header nav on mobile

**Testing:**
- âœ… Touch target audit (2026-01-25)
  - All buttons â‰¥48Ã—48px
  - All form inputs â‰¥48px height
  - Box corner handles â‰¥32Ã—32px

- â¬œ Keyboard shortcut testing (desktop)
  - All shortcuts work as documented
  - No conflicts with browser shortcuts

- â¬œ Device testing
  - iPhone Safari
  - Android Chrome
  - iPad Safari
  - Desktop Chrome/Firefox/Safari

- â¬œ Flow testing
  - Upload â†’ Select Questions â†’ Annotate â†’ Finalize â†’ Next
  - Consent flow blocks upload without agreement
  - AI model tracking recorded correctly

- âœ… Performance check (2026-01-25)
  - Lighthouse mobile performance: 98 (target >70)
  - Lighthouse accessibility: 100

---

**Sprint 3 Acceptance Criteria:**
- âœ… Contributor consent dialog appears before first upload/annotation
- âœ… Consent stored as Cognito custom attributes (custom:contributor, custom:consent_date)
- âœ… Question selection works on Upload screen
- âœ… Default questions auto-load by document type + language
- âœ… Question-by-question navigation works
- âœ… Box-first workflow: draw â†’ read/type â†’ next
- âœ… [ğŸ“– Read] button extracts text from bounding box
- âœ… AI model ID recorded when Read is used
- âœ… Progress dots show completion status
- âœ… Keyboard shortcuts work on desktop
- âœ… Finalize screen shows summary
- âœ… All pages responsive at 375px width
- âœ… Bottom navigation works on mobile
- âœ… Camera capture works on iOS/Android
- âœ… Touch bounding box drawing works
- âœ… All touch targets â‰¥48px
- âœ… Lighthouse mobile score >70

---

## Sprint 4: Dataset Export & Model Evaluation

**Goal**: Publish datasets to Hugging Face and run parallel model evaluations with ANLS/IoU metrics
**Duration**: 2-3 weeks
**Deliverable**: Manual dataset export to HF Hub, parallel model evaluation with W&B tracking
**Proposal**: See [spec/proposals/20260125_dataset_export_evaluation.md](proposals/20260125_dataset_export_evaluation.md)

### Key Design Decisions

| Decision | Choice | Rationale |
|----------|--------|-----------|
| Dataset Storage | Hugging Face Hub (not S3) | Avoid forcing users to download from our S3; HF handles hosting |
| Image Format | Compressed images embedded in Parquet | Self-contained dataset, no external dependencies |
| Coordinate Format | Normalized 0-1 range with width/height provided | Standard for VQA datasets, scale-independent |
| Primary Metrics | ANLS + IoU | DocVQA standard; ANLS for text, IoU for bounding boxes |
| Evaluation Config | JSON file in repo | Git-tracked, enables future auto-trigger on change |
| Trigger Method | Manual (UI buttons) | Simpler initial implementation; auto-trigger deferred |

---

### Phase 1: Foundation (Parallel Units A, B, E)

#### Unit A: Data Models

- â¬œ Update data schema in `amplify/data/resource.ts`
  ```typescript
  DatasetVersion: a.model({
    version: a.string().required(),           // e.g., "v1.0.0"
    huggingFaceRepoId: a.string().required(), // e.g., "icoxfog417/biz-doc-vqa"
    huggingFaceUrl: a.string().required(),    // Full URL
    annotationCount: a.integer().required(),
    imageCount: a.integer().required(),
    status: a.enum(['CREATING', 'READY', 'EVALUATING', 'FINALIZED']),
    createdAt: a.datetime().required(),
    finalizedAt: a.datetime(),
  }).authorization((allow) => [allow.authenticated()]),

  DatasetExportProgress: a.model({
    exportId: a.string().required(),
    version: a.string().required(),
    lastProcessedAnnotationId: a.string(),    // Checkpoint for resume
    processedCount: a.integer().required(),
    totalCount: a.integer().required(),
    status: a.enum(['IN_PROGRESS', 'COMPLETED', 'FAILED']),
    errorMessage: a.string(),
    startedAt: a.datetime().required(),
    updatedAt: a.datetime(),
  }).authorization((allow) => [allow.authenticated()]),

  EvaluationJob: a.model({
    jobId: a.string().required(),
    datasetVersion: a.string().required(),
    modelId: a.string().required(),
    status: a.enum(['QUEUED', 'RUNNING', 'COMPLETED', 'FAILED']),
    avgAnls: a.float(),                       // 0-1 scale
    avgIou: a.float(),                        // 0-1 scale
    totalSamples: a.integer(),
    wandbRunUrl: a.string(),
    errorMessage: a.string(),
    startedAt: a.datetime(),
    completedAt: a.datetime(),
  }).authorization((allow) => [allow.authenticated()]),
  ```

- â¬œ Deploy and test schema changes in sandbox

#### Unit B: Configuration File

- âœ… Create `src/config/evaluation-models.json`
  ```json
  {
    "version": "1.0",
    "models": [
      {
        "id": "claude-3-5-sonnet",
        "name": "Claude 3.5 Sonnet",
        "provider": "bedrock",
        "bedrockModelId": "anthropic.claude-3-5-sonnet-20241022-v2:0",
        "enabled": true
      },
      {
        "id": "amazon-nova-pro",
        "name": "Amazon Nova Pro",
        "provider": "bedrock",
        "bedrockModelId": "amazon.nova-pro-v1:0",
        "enabled": true
      }
    ],
    "metrics": {
      "primary": ["anls", "iou"],
      "anlsThreshold": 0.5,
      "iouThreshold": 0.5
    }
  }
  ```

- â¬œ Create `src/hooks/useEvaluationModels.ts` to load config

#### Unit E: SQS Queue Setup

- â¬œ Set up SQS queue for evaluation jobs in `amplify/backend.ts`
  ```typescript
  import * as sqs from 'aws-cdk-lib/aws-sqs';
  import { Duration } from 'aws-cdk-lib';

  const evaluationQueue = new sqs.Queue(stack, 'EvaluationJobQueue', {
    visibilityTimeout: Duration.minutes(15),
    retentionPeriod: Duration.days(7),
    deadLetterQueue: {
      queue: dlq,
      maxReceiveCount: 3
    }
  });
  ```

- â¬œ Grant Lambda functions access to queue

---

### Phase 2: Lambda Functions (Units C, D, F)

#### Unit C: Dataset Export Lambda (Python)

- â¬œ Store Hugging Face API token in AWS Secrets Manager
  ```bash
  printf "your-hf-token" | npx ampx sandbox secret set HF_TOKEN
  ```

- â¬œ Create `amplify/functions/export-dataset/` directory

- â¬œ Create `amplify/functions/export-dataset/resource.ts`
  ```typescript
  import { defineFunction, secret } from '@aws-amplify/backend';

  export const exportDataset = defineFunction({
    name: 'exportDataset',
    runtime: 20,
    timeoutSeconds: 900, // 15 minutes
    memoryMB: 2048,
    environment: {
      HF_TOKEN: secret('HF_TOKEN'),
      STORAGE_BUCKET_NAME: process.env.STORAGE_BUCKET_NAME,
    }
  });
  ```

- â¬œ Implement handler with checkpoint/resume capability
  - â¬œ Create DatasetExportProgress record at start
  - â¬œ Query approved annotations (status='APPROVED')
  - â¬œ Checkpoint every 100 annotations (update lastProcessedAnnotationId)
  - â¬œ Download compressed images from S3
  - â¬œ Normalize bounding boxes to 0-1 range
    ```python
    normalized_bbox = [
        bbox[0] / image['compressedWidth'],   # x0
        bbox[1] / image['compressedHeight'],  # y0
        bbox[2] / image['compressedWidth'],   # x1
        bbox[3] / image['compressedHeight'],  # y1
    ]
    ```
  - â¬œ Build dataset with HF datasets schema
    ```python
    features = Features({
        "question_id": Value("string"),
        "image": Image(),
        "image_width": Value("int32"),
        "image_height": Value("int32"),
        "question": Value("string"),
        "answers": Sequence(Value("string")),
        "answer_bbox": Sequence(Value("float32"), length=4),
        "document_type": Value("string"),
        "question_type": Value("string"),
        "language": Value("string"),
    })
    ```
  - â¬œ Push to Hugging Face Hub with version tag
  - â¬œ Update DatasetVersion record (status=READY)
  - â¬œ Handle errors and update progress to FAILED

- â¬œ Update `amplify/backend.ts` to include export-dataset function

#### Unit D: Evaluation Lambda (Python)

- â¬œ Store W&B API key in AWS Secrets Manager
  ```bash
  printf "your-wandb-api-key" | npx ampx sandbox secret set WANDB_API_KEY
  ```

- â¬œ Create `amplify/functions/run-evaluation/` directory

- â¬œ Create `amplify/functions/run-evaluation/resource.ts`
  ```typescript
  import { defineFunction, secret } from '@aws-amplify/backend';

  export const runEvaluation = defineFunction({
    name: 'runEvaluation',
    runtime: 20,
    timeoutSeconds: 900,
    memoryMB: 2048,
    environment: {
      WANDB_API_KEY: secret('WANDB_API_KEY'),
      WANDB_PROJECT: 'biz-doc-vqa',
    }
  });
  ```

- â¬œ Implement ANLS metric calculation
  ```python
  def calculate_anls(prediction: str, ground_truths: list, threshold: float = 0.5) -> float:
      """ANLS = 1 - NLD (Normalized Levenshtein Distance)"""
      max_anls = 0
      pred_norm = prediction.lower().strip()
      for gt in ground_truths:
          gt_norm = gt.lower().strip()
          lev_dist = levenshtein_distance(pred_norm, gt_norm)
          max_len = max(len(pred_norm), len(gt_norm), 1)
          anls = 1 - (lev_dist / max_len)
          if anls < threshold:
              anls = 0
          max_anls = max(max_anls, anls)
      return max_anls
  ```

- â¬œ Implement IoU metric calculation
  ```python
  def calculate_iou(pred_bbox: list, gt_bbox: list) -> float:
      """IoU for bounding boxes in normalized 0-1 coordinates [x0, y0, x1, y1]"""
      x1 = max(pred_bbox[0], gt_bbox[0])
      y1 = max(pred_bbox[1], gt_bbox[1])
      x2 = min(pred_bbox[2], gt_bbox[2])
      y2 = min(pred_bbox[3], gt_bbox[3])
      intersection = max(0, x2 - x1) * max(0, y2 - y1)
      pred_area = (pred_bbox[2] - pred_bbox[0]) * (pred_bbox[3] - pred_bbox[1])
      gt_area = (gt_bbox[2] - gt_bbox[0]) * (gt_bbox[3] - gt_bbox[1])
      union = pred_area + gt_area - intersection
      return intersection / union if union > 0 else 0
  ```

- â¬œ Implement evaluation handler
  - â¬œ Update EvaluationJob status to RUNNING
  - â¬œ Stream dataset from HF Hub
  - â¬œ Run model predictions via Bedrock (load model from config)
  - â¬œ Calculate ANLS and IoU per sample
  - â¬œ Log results incrementally to W&B
  - â¬œ Update EvaluationJob with final metrics (avgAnls, avgIou)
  - â¬œ Handle errors and update status to FAILED

- â¬œ Configure SQS trigger for parallel model evaluation
  ```typescript
  evaluationLambda.addEventSource(
    new SqsEventSource(evaluationQueue, {
      batchSize: 1,  // One model per Lambda invocation
      reportBatchItemFailures: true
    })
  );
  ```

#### Unit F: Trigger Lambda (Node.js)

- â¬œ Create `amplify/functions/trigger-evaluation/` directory

- â¬œ Create `amplify/functions/trigger-evaluation/resource.ts`

- â¬œ Implement handler
  - â¬œ Read enabled models from `evaluation-models.json`
  - â¬œ Create EvaluationJob records for each model (status=QUEUED)
  - â¬œ Send SQS messages for each model
  - â¬œ Return job IDs to caller

- â¬œ Add GraphQL mutation for manual trigger
  ```typescript
  triggerEvaluation: a.mutation()
    .arguments({
      datasetVersion: a.string().required(),
      modelIds: a.string().array(),  // Optional, defaults to all enabled
    })
    .returns(a.string().array())  // Returns job IDs
    .authorization((allow) => [allow.authenticated()])
    .handler(a.handler.function(triggerEvaluation)),
  ```

---

### Phase 3: Frontend UI (Unit G)

#### Unit G: Dataset Management Page

- â¬œ Create `src/pages/DatasetManagement.tsx`
  - â¬œ Dataset Versions section
    - â¬œ List all DatasetVersion records
    - â¬œ Show status badge (CREATING, READY, EVALUATING, FINALIZED)
    - â¬œ Display annotation count and image count
    - â¬œ Link to Hugging Face dataset page
  - â¬œ Export section
    - â¬œ "Create New Version" button
    - â¬œ Version input field (default: increment from latest)
    - â¬œ Show export progress (IN_PROGRESS, COMPLETED, FAILED)
    - â¬œ Display checkpoint info for resume capability
  - â¬œ Evaluation section
    - â¬œ Model selector (checkboxes from evaluation-models.json)
    - â¬œ Dataset version selector
    - â¬œ "Run Evaluation" button
    - â¬œ Evaluation jobs table
      - â¬œ Columns: Model, Status, ANLS, IoU, W&B Link
      - â¬œ Status badge component (QUEUED, RUNNING, COMPLETED, FAILED)
    - â¬œ Poll for status updates (every 10 seconds when jobs running)

- â¬œ Add navigation to DatasetManagement page
  - â¬œ Add link in Dashboard
  - â¬œ Add route in App.tsx

- â¬œ Update Dashboard
  - â¬œ Add "Latest Dataset" widget
  - â¬œ Show recent evaluation results summary
  - â¬œ Quick link to W&B project

---

### Phase 4: Testing & Documentation

- â¬œ Test dataset export
  - â¬œ Export 100+ annotations to HF Hub
  - â¬œ Verify Parquet format is correct
  - â¬œ Verify images are embedded correctly
  - â¬œ Verify bounding boxes are normalized (0-1 range)
  - â¬œ Test resume after simulated failure (checkpoint)

- â¬œ Test evaluation pipeline
  - â¬œ Run evaluation on test dataset
  - â¬œ Verify ANLS calculation matches manual check
  - â¬œ Verify IoU calculation matches manual check
  - â¬œ Test parallel model evaluation (multiple models)
  - â¬œ Check W&B dashboard shows comparison

- â¬œ Test error handling
  - â¬œ Simulate HF Hub upload failure
  - â¬œ Simulate Bedrock API failure
  - â¬œ Verify failed jobs show error messages
  - â¬œ Test DLQ for failed messages

- â¬œ Documentation
  - â¬œ Update README with dataset export workflow
  - â¬œ Document evaluation metrics (ANLS, IoU)
  - â¬œ Document evaluation-models.json configuration
  - â¬œ Create HF Hub dataset card template
  - â¬œ Document W&B project structure

**Sprint 4 Acceptance Criteria:**
- â¬œ Dataset export works for 1,000+ annotations
- â¬œ Resume works after simulated failure (checkpoint system)
- â¬œ ANLS/IoU metrics match manual calculation
- â¬œ W&B shows model comparison dashboard
- â¬œ Manual trigger from UI works end-to-end
- â¬œ Compressed images embedded in Parquet correctly
- â¬œ Bounding boxes normalized to 0-1 range
- â¬œ Unicode characters preserved (Japanese, Chinese text)
- â¬œ HF Hub dataset page accessible with correct schema
- â¬œ Multiple models can be evaluated in parallel

---

## Sprint 5: Multi-Language Support & Image Optimization

**Goal**: Support multiple languages and optimize image storage
**Duration**: 2 weeks
**Deliverable**: Multi-language annotation + image compression

### Multi-Language Data Model
- â¬œ Add language field to Image model
  ```typescript
  language: a.enum(['ja', 'en', 'zh', 'ko']).required()
  ```
- â¬œ Add language field to Annotation model
- â¬œ Add GSI on language field for filtering
- â¬œ Deploy schema updates

### Multi-Language UI
- â¬œ Add language selection to Upload page
  - â¬œ Language dropdown (Japanese, English, Chinese, Korean)
  - â¬œ Make language required field
  - â¬œ Display selected language prominently
- â¬œ Add language filter to Image Gallery
- â¬œ Display language badge on image cards
- â¬œ (Optional) Set up i18n framework for UI localization
  ```bash
  # Only if you need multi-language UI (not required for MVP)
  npm install react-i18next i18next
  ```
  Note: Can start with English-only UI and add translations later if needed

### Multi-Language Nemotron Prompts
- â¬œ Create prompt templates directory `amplify/functions/generate-annotation/prompts/`
  - â¬œ `ja.ts` - Japanese prompt template
  - â¬œ `en.ts` - English prompt template
  - â¬œ `zh.ts` - Chinese prompt template
  - â¬œ `ko.ts` - Korean prompt template
- â¬œ Update NemotronVisionClient to select prompt by language
- â¬œ Add language parameter to annotation generation Lambda
- â¬œ Test prompts for each language
- â¬œ Update Lambda environment variables
  ```typescript
  SUPPORTED_LANGUAGES: 'ja,en,zh,ko'
  ```

### Additional Bedrock Models
- â¬œ Request model access for Qwen-VL
- â¬œ Add model selection to annotation generation
- â¬œ Update BedrockVisionClient to support multiple models
  - â¬œ Claude 3.5 Sonnet (current)
  - â¬œ Qwen-VL (new)
- â¬œ Add model configuration to settings

### Frontend Updates
- â¬œ Create ProgressiveImageLoader component
  - â¬œ Load thumbnail first
  - â¬œ Load compressed image progressively
  - â¬œ Add "View Original" option
  - â¬œ Show loading progress
- â¬œ Update ImageViewer to use ProgressiveImageLoader
- â¬œ Display compression statistics in image metadata

### Settings Page
- â¬œ Create Settings page layout
- â¬œ Implement BedrockModelConfiguration panel
  - â¬œ Model selection dropdown
  - â¬œ Default language selection
  - â¬œ Parameter tuning (temperature, max tokens)
- â¬œ Save settings to user preferences (DynamoDB)

**Sprint 5 Acceptance Criteria:**
- âœ… Users can select language when uploading images
- âœ… Images can be filtered by language
- âœ… Bedrock prompts use appropriate language
- âœ… Multiple Bedrock models are supported
- âœ… Progressive image loading works
- âœ… Settings page allows model configuration

Note: Image compression tasks moved to Sprint 2. See [spec/proposals/20260111_move_compression_to_sprint2.md](proposals/20260111_move_compression_to_sprint2.md)

---

## Sprint 6: Advanced Mobile Features

**Goal**: Advanced mobile gestures, offline support, and polish
**Duration**: 2 weeks
**Deliverable**: Pinch-to-zoom, offline PWA, advanced gestures
**Note**: Basic mobile features (camera, touch, responsive) are in Sprint 3

### Advanced Gesture Support
- â¬œ Implement gesture library integration (Hammer.js or similar)
- â¬œ Pinch-to-zoom gesture support
  - â¬œ Two-finger pinch to zoom in/out
  - â¬œ Smooth zoom transitions
  - â¬œ Zoom level limits (0.5x - 4x)
- â¬œ Two-finger pan gesture
  - â¬œ Pan while zoomed
  - â¬œ Momentum scrolling
- â¬œ Long-press for context menu
- â¬œ Haptic feedback on interactions (where supported)

### Offline Support (PWA)
- â¬œ Configure service worker for offline caching
- â¬œ Cache static assets and app shell
- â¬œ Queue uploads when offline
- â¬œ Sync queued items when back online
- â¬œ Show offline indicator in UI
- â¬œ Add PWA manifest
  ```json
  {
    "name": "Business OCR Annotator",
    "short_name": "OCR Annotator",
    "start_url": "/",
    "display": "standalone"
  }
  ```

### Performance Optimization for Mobile
- â¬œ Implement lazy loading for images
- â¬œ Optimize bundle size
  ```bash
  npm install --save-dev webpack-bundle-analyzer
  ```
- â¬œ Code splitting for routes
- â¬œ Test on 3G/4G networks (throttling)
- â¬œ Measure page load times on mobile devices
- â¬œ Skeleton loading states for better perceived performance

### Common Components
- â¬œ Create NotificationToast component
- â¬œ Implement LoadingSpinner
- â¬œ Create ErrorBoundary
- â¬œ Implement ConfirmDialog (mobile-friendly)
- â¬œ Create Tooltip component
- â¬œ Implement ProgressBar

**Sprint 6 Acceptance Criteria:**
- âœ… Pinch-to-zoom works smoothly
- âœ… Two-finger pan gesture works while zoomed
- âœ… App works offline (basic functionality)
- âœ… Uploads queue when offline and sync when online
- âœ… PWA installable on mobile devices
- âœ… App performs well on slow networks
- âœ… Skeleton loading improves perceived performance

---

## Sprint 7: Dataset Publishing & PII Handling

**Goal**: Publish datasets to Hugging Face with PII redaction
**Duration**: 2 weeks
**Deliverable**: One-click dataset publishing with compliance

### Advanced Export Formats
- â¬œ Extend export Lambda to support multiple formats
  - â¬œ JSON (existing)
  - â¬œ JSONL (streaming format)
  - â¬œ Parquet (for HuggingFace)
- â¬œ Install Apache Arrow for Parquet export
  ```bash
  cd amplify/functions/export-dataset
  npm install apache-arrow parquetjs
  ```
- â¬œ Implement Parquet export formatter
  - â¬œ Design Parquet schema for nested structures
  - â¬œ Optimize row group size
  - â¬œ Add compression (Snappy)
  - â¬œ Validate output
- â¬œ Add bounding box normalization utilities
  - â¬œ Convert absolute pixels to 0-1 normalized
  - â¬œ Convert to 0-1000 (LayoutLM standard)
  - â¬œ Support both formats in export
- â¬œ Update ExportDialog to support all formats

### PII Detection & Redaction
- â¬œ Create `amplify/functions/pii-redactor/` directory
- â¬œ Create `amplify/functions/pii-redactor/resource.ts`
- â¬œ Implement PIIDetector service (multi-language)
  - â¬œ Japanese patterns (phone, names, addresses)
  - â¬œ English patterns (SSN, phone, emails)
  - â¬œ Chinese patterns (ID numbers, phone)
  - â¬œ Korean patterns (phone, names)
  - â¬œ Universal patterns (emails, credit cards)
- â¬œ Implement image redaction using Sharp
  - â¬œ Blur detected PII regions (Gaussian blur)
  - â¬œ Preserve quality outside redacted areas
  - â¬œ Generate redacted image version
- â¬œ Implement text redaction in annotations
  - â¬œ Replace PII with placeholders
  - â¬œ Log redaction actions for audit
- â¬œ Add PII scanning to dataset export process
- â¬œ Update `amplify/backend.ts` to include function

### PII Detection UI
- â¬œ Create PIIRedactionControls component
  - â¬œ "Scan for PII" button
  - â¬œ Display PII detection results with confidence
  - â¬œ Allow manual review and override
  - â¬œ Show redaction progress
- â¬œ Add PII handling options to ExportDialog
  - â¬œ Include (no redaction)
  - â¬œ Redact (blur images, replace text)
  - â¬œ Exclude (remove PII annotations)
- â¬œ Display PII warnings before export

### Hugging Face Integration
- â¬œ Create `amplify/functions/hf-publisher/` directory
- â¬œ Create `amplify/functions/hf-publisher/resource.ts`
- â¬œ Install Hugging Face Hub SDK
  ```bash
  npm install @huggingface/hub
  ```
- â¬œ Implement HuggingFace client
  - â¬œ Create dataset repository
  - â¬œ Upload Parquet files
  - â¬œ Generate dataset card (README.md)
    - â¬œ Multi-language dataset description
    - â¬œ Citation (BibTeX and APA)
    - â¬œ Licensing (CC BY-SA 4.0)
    - â¬œ Usage examples with datasets library
    - â¬œ Language distribution statistics
    - â¬œ Legal context for international users
  - â¬œ Add version tagging
  - â¬œ Store HF dataset URL in DynamoDB
- â¬œ Add HF API token management to Settings
- â¬œ Update `amplify/backend.ts` to include function

### Publishing UI
- â¬œ Add "Publish to Hugging Face" button to DatasetDetails
- â¬œ Create PublishDialog component
  - â¬œ HuggingFace organization selection
  - â¬œ Dataset name and description
  - â¬œ License selection
  - â¬œ PII handling options
  - â¬œ Language filter
  - â¬œ Preview dataset card
- â¬œ Implement publish workflow
- â¬œ Display publication status and HF URL
- â¬œ Handle API rate limits and errors

### Dataset Card Template
- â¬œ Create dataset card template
- â¬œ Include standard sections
  - â¬œ Dataset Description
  - â¬œ Dataset Structure
  - â¬œ Multi-language support
  - â¬œ Citation format
  - â¬œ PII handling procedures
  - â¬œ Usage examples
  - â¬œ Legal context

**Sprint 7 Acceptance Criteria:**
- âœ… Datasets can be exported in JSON, JSONL, Parquet
- âœ… Bounding box normalization works correctly
- âœ… PII detection identifies sensitive data
- âœ… PII can be redacted from images and text
- âœ… Datasets can be published to Hugging Face
- âœ… Dataset card is auto-generated
- âœ… Publication URL is stored and displayed

---

## Sprint 8: Production Readiness & Polish

**Goal**: Production-ready secure and monitored platform
**Duration**: 2 weeks
**Deliverable**: Secure, documented, monitored system

### Security Hardening
- â¬œ Implement input validation on all forms
- â¬œ Sanitize user inputs (prevent XSS)
- â¬œ Implement CSRF protection
- â¬œ Set up Content Security Policy headers
- â¬œ Enable HTTPS only (HSTS)
- â¬œ Review S3 bucket policies (least privilege)
- â¬œ Review IAM roles and policies
- â¬œ Enable AWS CloudTrail for audit logs
- â¬œ Set up AWS Config for compliance
- â¬œ Secure API keys in AWS Secrets Manager
  ```bash
  aws secretsmanager create-secret --name hf-api-token
  ```
- â¬œ Implement presigned URL expiration (1 hour)
- â¬œ Enable DynamoDB encryption at rest (verify)
- â¬œ Enable S3 encryption at rest (verify)

### Vulnerability Scanning
- â¬œ Set up npm audit
  ```bash
  npm audit
  ```
- â¬œ Integrate Snyk for security scanning
  ```bash
  npm install -g snyk
  snyk test
  ```
- â¬œ Fix identified vulnerabilities
- â¬œ Schedule regular security audits

### Monitoring & Logging
- â¬œ Set up CloudWatch dashboards
  - â¬œ Lambda error rates
  - â¬œ API latency
  - â¬œ Bedrock API failures
  - â¬œ Storage usage
  - â¬œ DynamoDB read/write capacity
- â¬œ Configure CloudWatch alarms
  - â¬œ High error rates (email notification)
  - â¬œ High latency (>3s)
  - â¬œ Storage nearing quota
- â¬œ Implement structured logging in Lambda functions
  ```typescript
  import { Logger } from '@aws-lambda-powertools/logger';
  const logger = new Logger();
  ```
- â¬œ Set up log aggregation (CloudWatch Insights)
- â¬œ Configure SNS notifications for critical alarms
  ```bash
  aws sns create-topic --name amplify-alerts
  ```

### Error Tracking
- â¬œ Integrate frontend error tracking (Sentry or Rollbar)
  ```bash
  npm install @sentry/react
  ```
- â¬œ Configure error reporting for Lambda functions
- â¬œ Set up error alert notifications
- â¬œ Create error triage workflow

### Performance Monitoring
- â¬œ Implement APM (Application Performance Monitoring)
- â¬œ Set up X-Ray tracing for Lambda functions
  ```typescript
  import { captureLambdaHandler } from '@aws-lambda-powertools/tracer';
  ```
- â¬œ Monitor database query performance
- â¬œ Monitor Bedrock API latency
- â¬œ Create performance optimization plan

### Backup & Recovery
- â¬œ Enable DynamoDB point-in-time recovery
  ```bash
  aws dynamodb update-continuous-backups \
    --table-name Image \
    --point-in-time-recovery-specification PointInTimeRecoveryEnabled=true
  ```
- â¬œ Enable S3 versioning for critical buckets
- â¬œ Create disaster recovery plan document
- â¬œ Document recovery procedures
- â¬œ Test backup restoration process

### Testing
- â¬œ Set up Jest testing framework
  ```bash
  npm install --save-dev jest @types/jest ts-jest
  ```
- â¬œ Write unit tests for utility functions
  - â¬œ Bounding box normalization
  - â¬œ PII detection patterns
  - â¬œ Image compression logic
- â¬œ Write tests for React components
  ```bash
  npm install --save-dev @testing-library/react
  ```
- â¬œ Write integration tests for Lambda functions
- â¬œ Set up E2E testing with Cypress/Playwright
  ```bash
  npm install --save-dev @playwright/test
  ```
- â¬œ Write E2E test for annotation workflow
- â¬œ Test across browsers (Chrome, Safari, Firefox)
- â¬œ Test responsive design on devices
- â¬œ Achieve >80% code coverage

### Performance Testing
- â¬œ Load test image upload (concurrent users)
- â¬œ Load test annotation generation
- â¬œ Test compression with various image sizes
- â¬œ Test on simulated mobile networks
- â¬œ Optimize slow queries and operations

### Documentation
- â¬œ Create user guide for curators
- â¬œ Create user guide for annotators
- â¬œ Document API endpoints
- â¬œ Create architecture diagrams
  ```bash
  npm install --save-dev mermaid
  ```
- â¬œ Document deployment process
- â¬œ Create troubleshooting guide
- â¬œ Document Bedrock integration
- â¬œ Create video tutorials (optional)

### CI/CD Pipeline
- â¬œ Set up GitHub Actions workflow
  ```yaml
  # .github/workflows/deploy.yml
  name: Deploy to Amplify
  on: [push]
  jobs:
    deploy:
      runs-on: ubuntu-latest
      steps:
        - uses: actions/checkout@v3
        - run: npm ci
        - run: npm test
        - run: npx ampx pipeline-deploy
  ```
- â¬œ Configure automated testing on PR
- â¬œ Set up staging environment
- â¬œ Configure production deployment
- â¬œ Add deployment approval workflow

### Launch Preparation
- â¬œ Complete security review checklist
- â¬œ Complete performance testing
- â¬œ Verify all monitoring is active
- â¬œ Create launch plan document
- â¬œ Prepare rollback plan
- â¬œ Train initial users
- â¬œ Set up support channels (email, chat)
- â¬œ Prepare announcement (blog post, social media)

**Sprint 8 Acceptance Criteria:**
- âœ… Security scan passes with no critical issues
- âœ… All monitoring dashboards are active
- âœ… Error tracking is configured
- âœ… Backup and recovery tested
- âœ… Test coverage >80%
- âœ… Documentation is complete
- âœ… CI/CD pipeline is operational
- âœ… Ready for production launch

---

## Post-Launch: Maintenance & Enhancements

### Launch Activities
- â¬œ Deploy to production
  ```bash
  npx ampx pipeline-deploy --branch main
  ```
- â¬œ Monitor for issues (first 48 hours)
- â¬œ Collect initial user feedback
- â¬œ Address critical issues immediately
- â¬œ Publish announcement
- â¬œ Conduct retrospective meeting

### Post-Launch Optimization
- â¬œ Analyze user behavior with analytics
- â¬œ Identify bottlenecks and optimize
- â¬œ Gather feature requests
- â¬œ Prioritize roadmap
- â¬œ Plan next sprint

---

## Future Enhancements (Backlog)

### Advanced Features
- â¬œ Multi-annotator consensus workflow
- â¬œ Real-time collaboration on annotations
- â¬œ Advanced analytics dashboard with ML insights
- â¬œ Custom model training pipeline
- â¬œ Native mobile app (React Native)
- â¬œ Public API for programmatic access
- â¬œ Webhook integrations
- â¬œ Annotation templates and presets
- â¬œ Bulk operations (batch approve/delete)
- â¬œ Dataset versioning with diff view
- â¬œ Annotation quality scoring

### Additional Integrations
- â¬œ Integration with Label Studio
- â¬œ Integration with CVAT
- â¬œ Support for GPT-4V model
- â¬œ Export to COCO format
- â¬œ Export to Pascal VOC format
- â¬œ Integration with Labelbox
- â¬œ IIIF (International Image Interoperability Framework) support

### Infrastructure Enhancements
- â¬œ Multi-region deployment
- â¬œ CDN for global performance (CloudFront)
- â¬œ Redis caching layer for API responses
- â¬œ Dataset partitioning for large collections
- â¬œ Database migration to Aurora (if needed)
- â¬œ Implement search with OpenSearch

### Advanced AI Features
- â¬œ Support for additional Bedrock models
- â¬œ Custom prompt engineering interface
- â¬œ Active learning to improve annotation quality
- â¬œ Automated quality assessment
- â¬œ Confidence scoring for annotations

---

## Amplify Gen2 Command Reference

### Development Commands
```bash
# Initialize new Amplify project
npm create amplify@latest

# Install Amplify dependencies
npm install aws-amplify @aws-amplify/ui-react
npm install --save-dev @aws-amplify/backend @aws-amplify/backend-cli

# Start local sandbox (with hot reload)
npx ampx sandbox

# Stream function logs while in sandbox
npx ampx sandbox --stream-function-logs

# Filter logs from specific functions
npx ampx sandbox --logs-filter "generateAnnotation"

# Generate GraphQL client types
npx ampx generate graphql-client-code

# Delete sandbox
npx ampx sandbox delete
```

### Deployment Commands
```bash
# Deploy to Amplify (production)
npx ampx pipeline-deploy --branch main

# Deploy to staging
npx ampx pipeline-deploy --branch staging

# Check deployment status
aws amplify list-apps
```

### AWS Configuration
```bash
# Configure AWS credentials
aws configure

# Create secrets for sensitive data
aws secretsmanager create-secret --name hf-api-token --secret-string "your-token"

# Enable Bedrock model access (via AWS Console)
# Navigate to: Amazon Bedrock > Model access > Request model access
```

### Testing Commands
```bash
# Run unit tests
npm test

# Run E2E tests
npx playwright test

# Security audit
npm audit
snyk test

# Bundle analysis
npm run build
npx webpack-bundle-analyzer build/stats.json
```

---

## Amplify Gen2 File Structure

```
business-ocr-annotator/
â”œâ”€â”€ amplify/
â”‚   â”œâ”€â”€ auth/
â”‚   â”‚   â””â”€â”€ resource.ts           # defineAuth()
â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â””â”€â”€ resource.ts           # defineStorage()
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ resource.ts           # defineData() with schema
â”‚   â”œâ”€â”€ functions/
â”‚   â”‚   â”œâ”€â”€ generate-annotation/
â”‚   â”‚   â”‚   â”œâ”€â”€ resource.ts       # defineFunction()
â”‚   â”‚   â”‚   â”œâ”€â”€ handler.ts        # Lambda handler
â”‚   â”‚   â”‚   â””â”€â”€ package.json
â”‚   â”‚   â”œâ”€â”€ export-dataset/
â”‚   â”‚   â”‚   â”œâ”€â”€ resource.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ handler.ts
â”‚   â”‚   â”‚   â””â”€â”€ package.json
â”‚   â”‚   â”œâ”€â”€ image-processor/
â”‚   â”‚   â”‚   â”œâ”€â”€ resource.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ handler.ts
â”‚   â”‚   â”‚   â””â”€â”€ package.json
â”‚   â”‚   â”œâ”€â”€ pii-redactor/
â”‚   â”‚   â”‚   â”œâ”€â”€ resource.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ handler.ts
â”‚   â”‚   â”‚   â””â”€â”€ package.json
â”‚   â”‚   â””â”€â”€ hf-publisher/
â”‚   â”‚       â”œâ”€â”€ resource.ts
â”‚   â”‚       â”œâ”€â”€ handler.ts
â”‚   â”‚       â””â”€â”€ package.json
â”‚   â””â”€â”€ backend.ts                # defineBackend() - imports all resources
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ App.tsx
â”‚   â””â”€â”€ main.tsx                  # Vite entry point
â”œâ”€â”€ public/                       # Static assets
â”œâ”€â”€ index.html                    # HTML entry point (Vite)
â”œâ”€â”€ amplify_outputs.json          # Generated after deployment
â”œâ”€â”€ vite.config.ts                # Vite configuration
â”œâ”€â”€ package.json
â””â”€â”€ tsconfig.json
```

---

## Risk Management

### Known Risks
1. **Bedrock Model Availability**: Dependency on external model API
   - Mitigation: Multiple model options, robust error handling

2. **Hugging Face API Limits**: Rate limiting and quotas
   - Mitigation: Retry logic, batch operations, upgrade plan if needed

3. **Dataset Size**: Large datasets may impact performance
   - Mitigation: Pagination, lazy loading, partitioning

4. **Annotation Quality**: AI-generated annotations may have errors
   - Mitigation: Human validation workflow, confidence thresholds

5. **Cost Overruns**: AWS and Bedrock costs may exceed budget
   - Mitigation: Monitor costs, implement limits, optimize storage

6. **Mobile Browser Compatibility**: Camera API may vary across devices
   - Mitigation: Fallback mechanisms, progressive enhancement, testing

---

## Progress Tracking

**Last Review Date**: 2026-01-25
**Next Review Date**: TBD
**Completed Tasks**: Sprint 0 + Sprint 1 + Sprint 2 completed
**Current Sprint**: Sprint 4 (Dataset Export & Model Evaluation)

### Sprint Completion Status
- âœ… Sprint 0: Foundation & Deployment
- âœ… Sprint 1: Image Upload & Manual Annotation (MVP)
- âœ… Sprint 2: AI-Assisted Annotation
- âœ… Sprint 3: UX & Mobile UI Optimization
- â¬œ Sprint 4: Dataset Export & Model Evaluation
- â¬œ Sprint 5: Multi-Language Support & Optimization
- â¬œ Sprint 6: Advanced Mobile Features
- â¬œ Sprint 7: Publishing & PII Handling
- â¬œ Sprint 8: Production Readiness

### Deferred from Sprint 2
- â¬œ Per-user contribution tracking (REQ-AW-013, REQ-AW-014)
  - Requires User model implementation
  - Currently shows global stats only (Dashboard displays AI vs Human counts)
- â¬œ Test model inference with sample images
  - Using mock fallback implementation currently
  - DefaultQuestionManager uses fallback question generation

---

## Notes

- **Agile Approach**: Each sprint delivers working, deployable software
- **User Feedback**: Collect feedback after Sprints 1, 2, and 3
- **Incremental Complexity**: Start simple, add features gradually
- **Integration**: Frontend and backend tasks are integrated per sprint
- **Flexibility**: Sprint order can be adjusted based on priorities
- **Documentation**: Update this file after each sprint completion
- **Proposals**: Create proposal documents for significant changes

---

## Sources & References

- [AWS Amplify Gen2 Documentation](https://docs.amplify.aws/)
- [CLI Commands Reference](https://docs.amplify.aws/react/reference/cli-commands/)
- [Sandbox Features](https://docs.amplify.aws/react/deploy-and-host/sandbox-environments/features/)
- [create-amplify npm package](https://www.npmjs.com/package/create-amplify)
- [Amplify Storage with TypeScript](https://aws.amazon.com/blogs/mobile/amplify-storage-now-with-fullstack-typescript-powered-by-amazon-s3/)
